{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0293b07-d50b-440f-a8e9-255aa925a6d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wine Quality Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9457a-4696-4ebb-bb20-697436d93e82",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59039a0-b3c3-4023-830f-662605bea056",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Multinomial Logistic Regression\n",
    "\n",
    "<strong>Type</strong>: Classification </p>\n",
    "<strong>UCI Open Source Dataset</strong>: [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality) </p>\n",
    "\n",
    "This dataset contains red and white vinho verde wine samples, from the north of Portugal, and wine quality data based on physicochemical tests [Cortez et al., 2009](http://www3.dsi.uminho.pt/pcortez/wine/). \n",
    "\n",
    "<strong>Problem</strong>: Imagine you are a wine specialist who is looking for an automated way to categorize the wines you find based on wine quality data from physicochemical tests. You could use a machine learning algorithm to train a model that would be able to predict the quality of a wine based on its physicochemical properties. This would allow you to quickly and easily categorize new wines that you find, without having to manually taste them.\n",
    "\n",
    "Here are some of the benefits of using an automated wine categorization system:\n",
    "\n",
    "- <strong>Speed</strong>: An automated system can categorize wines much faster than a human can. This is especially beneficial for wine retailers and distributors who need to quickly categorize large numbers of wines.\n",
    "- <strong>Accuracy</strong>: An automated system can be more accurate than a human when it comes to categorizing wines. This is because the system is not influenced by personal biases or preferences.\n",
    "- <strong>Consistency</strong>: An automated system will consistently categorize wines in the same way, which can help to ensure that customers are getting the wines they expect.\n",
    "\n",
    "If you are a wine specialist who is looking for an efficient and accurate way to categorize wines, then an automated system may be the perfect solution for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e5893-eb68-4721-b083-da5b40f78ac4",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5377b0f3-bfdd-4153-a4b4-889962048eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage, aiplatform, exceptions\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aae3c7-b31d-42d6-bbe1-defe4057b24f",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b252e0d9-a2a9-4cb4-944b-ee1cc5e9132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_URL = \"http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip\"\n",
    "BUCKET_NAME = \"dataproc-workspaces-notebooks-wine-quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9ea5e-8d93-49bc-ad30-3801391a9408",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create a bucket to handle training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d1df4a-67b9-4a9b-9873-b217489f1d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket dataproc-workspaces-notebooks-wine-quality already created\n"
     ]
    }
   ],
   "source": [
    "# Creating directory to store dataset\n",
    "def create_bucket_class_location(bucket_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    bucket.storage_class = \"STANDARD\"\n",
    "    try:\n",
    "        new_bucket = storage_client.create_bucket(bucket, location=\"us\")\n",
    "        print(\n",
    "            \"Created bucket {} in {} with storage class {}\".format(\n",
    "                new_bucket.name, new_bucket.location, new_bucket.storage_class\n",
    "            )\n",
    "        )\n",
    "        return new_bucket\n",
    "    except exceptions.Conflict:\n",
    "        print(\n",
    "            \"Bucket {} already created\".format(bucket_name)\n",
    "        )\n",
    "    finally:\n",
    "        return bucket_name\n",
    "\n",
    "bucket_name = create_bucket_class_location(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1e48f9-9ed1-467f-bc57-8ea8aff89704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-16 02:06:39--  http://www3.dsi.uminho.pt/pcortez/wine/winequality.zip\n",
      "Resolving www3.dsi.uminho.pt (www3.dsi.uminho.pt)... 193.136.11.133\n",
      "Connecting to www3.dsi.uminho.pt (www3.dsi.uminho.pt)|193.136.11.133|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96005 (94K) [application/x-zip-compressed]\n",
      "Saving to: ‘winequality.zip.18’\n",
      "\n",
      "winequality.zip.18  100%[===================>]  93.75K   396KB/s    in 0.2s    \n",
      "\n",
      "2023-06-16 02:06:40 (396 KB/s) - ‘winequality.zip.18’ saved [96005/96005]\n",
      "\n",
      "Archive:  winequality.zip\n",
      "  inflating: winequality/winequality-names.txt  \n",
      "  inflating: winequality/winequality-names.txt.bak  \n",
      "  inflating: winequality/winequality-red.csv  \n",
      "  inflating: winequality/winequality-white.csv  \n",
      "Copying file://winequality/winequality-names.txt [Content-Type=text/plain]...\n",
      "Copying file://winequality/winequality-names.txt.bak [Content-Type=application/x-trash]...\n",
      "Copying file://winequality/winequality-red.csv [Content-Type=text/csv]...       \n",
      "Copying file://winequality/winequality-white.csv [Content-Type=text/csv]...     \n",
      "- [4 files][346.0 KiB/346.0 KiB]                                                \n",
      "Operation completed over 4 objects/346.0 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Download the raw .zip data by copying the data to cloud storage bucket.\n",
    "!wget $TRAIN_DATASET_URL\n",
    "!unzip -o winequality.zip \n",
    "!gsutil cp winequality/* gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd099d7-9b79-412f-9cc6-421b281b2d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eee0eaa-4890-4a7a-bd96-fb59ee658b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Multinomial logistic regression Wine Quality\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a095a2-a582-4360-8aca-310be6635296",
   "metadata": {},
   "source": [
    "### Import and parse the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0a6ea6-95f7-44cb-bcef-e25132b5463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.\\\n",
    "    options(inferSchema='True',delimiter=';',header='True'). \\\n",
    "    csv(\"gs://{}/winequality-white.csv\".\n",
    "        format(BUCKET_NAME)\n",
    "       )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26707730-739c-4946-aa4b-1d8375b68c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.0|            0.27|       0.36|          20.7|    0.045|               45.0|               170.0|  1.001| 3.0|     0.45|    8.8|      6|\n",
      "|          6.3|             0.3|       0.34|           1.6|    0.049|               14.0|               132.0|  0.994| 3.3|     0.49|    9.5|      6|\n",
      "|          8.1|            0.28|        0.4|           6.9|     0.05|               30.0|                97.0| 0.9951|3.26|     0.44|   10.1|      6|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee393d03-4f05-42ce-b9bd-d773a57f6494",
   "metadata": {},
   "source": [
    "### DataFrame Column Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94e725-fedf-4eef-9ba7-b3b8810f3012",
   "metadata": {},
   "source": [
    "DataFrames may have heterogenous or \"mixed\" data types, that is, some columns are numbers, some are strings, and some are dates etc. Because CSV files do not contain information on what data types are contained in each column, Pandas infers the data types when loading the data, e.g. if a column contains only numbers, Pandas will set that column’s data type to numeric: integer or float.\n",
    "\n",
    "Run the next cell to see information on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3649f263-ea02-4660-91bf-5cec489dd1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed acidity: double (nullable = true)\n",
      " |-- volatile acidity: double (nullable = true)\n",
      " |-- citric acid: double (nullable = true)\n",
      " |-- residual sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free sulfur dioxide: double (nullable = true)\n",
      " |-- total sulfur dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329201b2-9b22-4c41-940f-cefdfc92b525",
   "metadata": {},
   "source": [
    "### Summary Statistics \n",
    "\n",
    "At this point, we have all columns contains numerical values. For features which contain numerical values, we are often interested in various statistical measures relating to those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9378955-696c-4a1f-a44f-6401dbd5d5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-------------------+-----------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|     fixed acidity|   volatile acidity|        citric acid|   residual sugar|           chlorides|free sulfur dioxide|total sulfur dioxide|             density|                 pH|          sulphates|           alcohol|           quality|\n",
      "+-------+------------------+-------------------+-------------------+-----------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|              4898|               4898|               4898|             4898|                4898|               4898|                4898|                4898|               4898|               4898|              4898|              4898|\n",
      "|   mean| 6.854787668436075|0.27824111882401087|0.33419150673743736|6.391414863209486|  0.0457723560636995|  35.30808493262556|  138.36065741118824|  0.9940273764801896| 3.1882666394446693| 0.4898468762760325|10.514267047774638|  5.87790935075541|\n",
      "| stddev|0.8438682276875127|0.10079454842486532|0.12101980420298254|5.072057784014878|0.021847968093728805|  17.00713732523259|  42.498064554142985|0.002990906916936997|0.15100059961506673|0.11412583394883222|  1.23062056775732|0.8856385749678322|\n",
      "|    min|               3.8|               0.08|                0.0|              0.6|               0.009|                2.0|                 9.0|             0.98711|               2.72|               0.22|               8.0|                 3|\n",
      "|    max|              14.2|                1.1|               1.66|             65.8|               0.346|              289.0|               440.0|             1.03898|               3.82|               1.08|              14.2|                 9|\n",
      "+-------+------------------+-------------------+-------------------+-----------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21c0b9-1b62-4e4c-b9c8-673d802ef0c5",
   "metadata": {},
   "source": [
    "Let's investigate a bit more of our target data by using the .groupby() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02466b00-d9ba-4a5f-b47e-e3c83982253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, isnan, sum, when, count\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60cd56e-1d9f-43f3-84f4-8a0b696a620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|quality|count|\n",
      "+-------+-----+\n",
      "|      6| 2198|\n",
      "|      3|   20|\n",
      "|      5| 1457|\n",
      "|      9|    5|\n",
      "|      4|  163|\n",
      "|      8|  175|\n",
      "|      7|  880|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\n",
    "    col('quality')).\\\n",
    "    count().\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e23ae-3904-4fdc-99b7-539cf4aa5609",
   "metadata": {},
   "source": [
    "We can see here that the data is <b>imbalanced</b> for our target. <b>Imbalanced</b> data is a common problem in machine learning, where the number of samples in one class is much larger than the number of samples in another class. This can make it difficult to train a model that can accurately predict the minority class. There are a number of techniques that can be used to handle imbalanced data, including:\n",
    "\n",
    "- <b>Resampling</b>: This involves increasing the number of samples in the minority class or decreasing the number of samples in the majority class. This can be done by oversampling the minority class (creating new samples), undersampling the majority class (removing samples), or a combination of both.\n",
    "- <b>Cost-sensitive learning</b>: This involves assigning different costs to misclassifications of different classes. This can help to focus the model on correctly classifying the minority class.\n",
    "- <b>Ensemble learning</b>: This involves training multiple models on different subsets of the data and then combining the predictions of the models. This can help to improve the accuracy of the model on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101507c8-b4ab-432d-8b0f-0eaeadbc55d7",
   "metadata": {},
   "source": [
    "We need to <b>resample</b> the data to balance the dataset. However, before we do that, we need to check if there are any issues with the data that need to be resolved. For example, we need to make sure that there are no missing values in the data. We also need to make sure that the data is not corrupted. Once we have resolved any issues with the data, we can then resample it to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974fcc1-3ed1-4e6d-a9ee-a7cea7733e4b",
   "metadata": {},
   "source": [
    "### DataFrame Column Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4609c-a771-41c8-ac8f-042b59779f85",
   "metadata": {},
   "source": [
    "DataFrames may have heterogenous or \"mixed\" data types, that is, some columns are numbers, some are strings, and some are dates etc. Because CSV files do not contain information on what data types are contained in each column, Pandas infers the data types when loading the data, e.g. if a column contains only numbers, Pandas will set that column’s data type to numeric: integer or float.\n",
    "\n",
    "Run the next cell to see information on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98cd535f-51d2-4b47-922a-9ae8d95df88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed acidity: double (nullable = true)\n",
      " |-- volatile acidity: double (nullable = true)\n",
      " |-- citric acid: double (nullable = true)\n",
      " |-- residual sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free sulfur dioxide: double (nullable = true)\n",
      " |-- total sulfur dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089dd53c-3a65-4c1e-90cc-452252dd13b7",
   "metadata": {},
   "source": [
    "### Summary Statistics \n",
    "\n",
    "At this point, we have all columns contains numerical values. For features which contain numerical values, we are often interested in various statistical measures relating to those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceddaed6-39a8-400e-8a51-743b030d19d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-------------------+-----------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|     fixed acidity|   volatile acidity|        citric acid|   residual sugar|           chlorides|free sulfur dioxide|total sulfur dioxide|             density|                 pH|          sulphates|           alcohol|           quality|\n",
      "+-------+------------------+-------------------+-------------------+-----------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|              4898|               4898|               4898|             4898|                4898|               4898|                4898|                4898|               4898|               4898|              4898|              4898|\n",
      "|   mean| 6.854787668436075|0.27824111882401087|0.33419150673743736|6.391414863209486|  0.0457723560636995|  35.30808493262556|  138.36065741118824|  0.9940273764801896| 3.1882666394446693| 0.4898468762760325|10.514267047774638|  5.87790935075541|\n",
      "| stddev|0.8438682276875127|0.10079454842486532|0.12101980420298254|5.072057784014878|0.021847968093728805|  17.00713732523259|  42.498064554142985|0.002990906916936997|0.15100059961506673|0.11412583394883222|  1.23062056775732|0.8856385749678322|\n",
      "|    min|               3.8|               0.08|                0.0|              0.6|               0.009|                2.0|                 9.0|             0.98711|               2.72|               0.22|               8.0|                 3|\n",
      "|    max|              14.2|                1.1|               1.66|             65.8|               0.346|              289.0|               440.0|             1.03898|               3.82|               1.08|              14.2|                 9|\n",
      "+-------+------------------+-------------------+-------------------+-----------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab092e4-ed42-48fc-bb58-e277cf8d145d",
   "metadata": {},
   "source": [
    "Let's investigate a bit more of our target data by using the .groupby() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78be86e2-2c53-43e1-969b-669a00ccf8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, isnan, sum, when, count\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ca6847b-9366-4bed-b6e3-9f4ddd9a2db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|quality|count|\n",
      "+-------+-----+\n",
      "|      6| 2198|\n",
      "|      3|   20|\n",
      "|      5| 1457|\n",
      "|      9|    5|\n",
      "|      4|  163|\n",
      "|      8|  175|\n",
      "|      7|  880|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\n",
    "    col('quality')).\\\n",
    "    count().\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569083aa-79b5-4b48-b183-5d04172406d5",
   "metadata": {},
   "source": [
    "We can see here that the data is <b>imbalanced</b> for our target. <b>Imbalanced</b> data is a common problem in machine learning, where the number of samples in one class is much larger than the number of samples in another class. This can make it difficult to train a model that can accurately predict the minority class. There are a number of techniques that can be used to handle imbalanced data, including:\n",
    "\n",
    "- <b>Resampling</b>: This involves increasing the number of samples in the minority class or decreasing the number of samples in the majority class. This can be done by oversampling the minority class (creating new samples), undersampling the majority class (removing samples), or a combination of both.\n",
    "- <b>Cost-sensitive learning</b>: This involves assigning different costs to misclassifications of different classes. This can help to focus the model on correctly classifying the minority class.\n",
    "- <b>Ensemble learning</b>: This involves training multiple models on different subsets of the data and then combining the predictions of the models. This can help to improve the accuracy of the model on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b847b372-0ccc-4ebb-81a8-51bcc52d821e",
   "metadata": {},
   "source": [
    "We need to <b>resample</b> the data to balance the dataset. However, before we do that, we need to check if there are any issues with the data that need to be resolved. For example, we need to make sure that there are no missing values in the data. We also need to make sure that the data is not corrupted. Once we have resolved any issues with the data, we can then resample it to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddec5b6-35ec-4142-9045-4a3e049fdec2",
   "metadata": {},
   "source": [
    "### Let's summarize our data by row, column, features, unique, and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a4a9c8-11cf-4652-91ce-56af6232bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows     :  4898\n",
      "Columns  :  12\n",
      "\n",
      "Features : \n",
      " ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
      "\n",
      " Count Distinct values :  \n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+---+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density| pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+---+---------+-------+-------+\n",
      "|           68|             125|         87|           310|      160|                132|                 251|    890|103|       79|    103|      7|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+---+---------+-------+-------+\n",
      "\n",
      "\n",
      "Unique values :  \n",
      " None\n",
      "\n",
      "Missing values :   \n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+---+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density| pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+---+---------+-------+-------+\n",
      "|            0|               0|          0|             0|        0|                  0|                   0|      0|  0|        0|      0|      0|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+---+---------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python shape() is used in pandas to give the number of rows/columns.\n",
    "# The number of rows is given by .shape[0]. The number of columns is given by .shape[1].\n",
    "# Thus, shape() consists of an array having two arguments -- rows and columns\n",
    "\n",
    "print (\"Rows     : \" ,df.count())\n",
    "print (\"Columns  : \" ,len(df.columns))\n",
    "print (\"\\nFeatures : \\n\" ,df.columns)\n",
    "print (\"\\n Count Distinct values : \", \"\")\n",
    "expression = [countDistinct(c).alias(c) for c in df.columns]\n",
    "print (\"\\nUnique values :  \\n\", df.select(*expression).show())\n",
    "print (\"\\nMissing values :  \", \"\")\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f22c89-83b6-4820-a72e-5eb12e393ee1",
   "metadata": {},
   "source": [
    "There no missing values, or other data issue. So we can ressample the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f18b8-5879-43c2-b04b-df45061210eb",
   "metadata": {},
   "source": [
    "### Rename a Feature Column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7de40f-ec11-4232-b165-967d013eb27e",
   "metadata": {},
   "source": [
    "Our feature columns have different \"capitalizations\" in their names, e.g. both upper and lower \"case\".  In addition, there are \"spaces\" in some of the column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19730bcd-71c5-4247-b0af-3da9932b3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"fixed acidity\",\"fixed_acidity\")\\\n",
    ".withColumnRenamed(\"volatile acidity\",\"volatile_acidity\")\\\n",
    ".withColumnRenamed(\"citric acid\",\"citric_acid\")\\\n",
    ".withColumnRenamed(\"residual sugar\",\"residual_sugar\")\\\n",
    ".withColumnRenamed(\"chlorides\",\"chlorides\")\\\n",
    ".withColumnRenamed(\"free sulfur dioxide\",\"free_sulfur_dioxide\")\\\n",
    ".withColumnRenamed(\"total sulfur dioxide\",\"total_sulfur_dioxide\")\\\n",
    ".withColumnRenamed(\"density\",\"density\")\\\n",
    ".withColumnRenamed(\"pH\",\"pH\")\\\n",
    ".withColumnRenamed(\"sulphates\",\"sulphates\")\\\n",
    ".withColumnRenamed(\"alcohol\",\"alcohol\")\\\n",
    ".withColumnRenamed(\"quality\",\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad4177e6-249b-4b30-aa4f-f152898d2fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed_acidity: double (nullable = true)\n",
      " |-- volatile_acidity: double (nullable = true)\n",
      " |-- citric_acid: double (nullable = true)\n",
      " |-- residual_sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free_sulfur_dioxide: double (nullable = true)\n",
      " |-- total_sulfur_dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014e0be-2875-4a65-9346-a2acb841df1e",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb63754-1120-4e01-8695-a6f0bf4ab59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ddba0-5fae-4383-ba2d-cc3461555216",
   "metadata": {},
   "source": [
    "## 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2e35c-7306-4e3a-a6da-ced25b3a4271",
   "metadata": {},
   "source": [
    "<b>Feature engineering</b> is the process of transforming raw data into features that are more informative and useful for machine learning algorithms. This can involve a variety of tasks, such as:\n",
    "\n",
    "- <b>Data transformation</b>: This involves transforming the data into a format that is more suitable for machine learning algorithms. For example, categorical data can be encoded as numerical data, and continuous data can be discretized.\n",
    "- <b>Feature selection</b>: This involves selecting the most important features from the data set. This can be done using a variety of techniques, such as statistical significance tests and feature importance scores.\n",
    "- <b>Feature creation</b>: This involves creating new features from the existing data. This can be done by combining existing features, or by creating derived features that are based on the relationships between different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "182c3714-22ca-4d7d-b00e-cd8165ec4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "092a7dd0-0b9d-4bf9-93bf-cf502ec6e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def create_quality_groups(score):\n",
    "    if score in [1,2,3]:\n",
    "        return 'poor'\n",
    "    elif score in [4,5]:\n",
    "        return 'normal'\n",
    "    elif score in [6,7,8]:\n",
    "        return 'good'\n",
    "    elif score in [9]:\n",
    "        return 'excelent'\n",
    "    return 'not defined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50829adb-df79-48b7-912f-628497b743c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_group = F.udf(\n",
    "    lambda q: create_quality_groups(q),\n",
    "    T.StringType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7d3ee52-2941-48df-8668-38615582bc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed_acidity|volatile_acidity|citric_acid|residual_sugar|chlorides|free_sulfur_dioxide|total_sulfur_dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.0|            0.27|       0.36|          20.7|    0.045|               45.0|               170.0|  1.001| 3.0|     0.45|    8.8|   good|\n",
      "|          6.3|             0.3|       0.34|           1.6|    0.049|               14.0|               132.0|  0.994| 3.3|     0.49|    9.5|   good|\n",
      "|          8.1|            0.28|        0.4|           6.9|     0.05|               30.0|                97.0| 0.9951|3.26|     0.44|   10.1|   good|\n",
      "|          7.2|            0.23|       0.32|           8.5|    0.058|               47.0|               186.0| 0.9956|3.19|      0.4|    9.9|   good|\n",
      "|          7.2|            0.23|       0.32|           8.5|    0.058|               47.0|               186.0| 0.9956|3.19|      0.4|    9.9|   good|\n",
      "|          8.1|            0.28|        0.4|           6.9|     0.05|               30.0|                97.0| 0.9951|3.26|     0.44|   10.1|   good|\n",
      "|          6.2|            0.32|       0.16|           7.0|    0.045|               30.0|               136.0| 0.9949|3.18|     0.47|    9.6|   good|\n",
      "|          7.0|            0.27|       0.36|          20.7|    0.045|               45.0|               170.0|  1.001| 3.0|     0.45|    8.8|   good|\n",
      "|          6.3|             0.3|       0.34|           1.6|    0.049|               14.0|               132.0|  0.994| 3.3|     0.49|    9.5|   good|\n",
      "|          8.1|            0.22|       0.43|           1.5|    0.044|               28.0|               129.0| 0.9938|3.22|     0.45|   11.0|   good|\n",
      "|          8.1|            0.27|       0.41|          1.45|    0.033|               11.0|                63.0| 0.9908|2.99|     0.56|   12.0| normal|\n",
      "|          8.6|            0.23|        0.4|           4.2|    0.035|               17.0|               109.0| 0.9947|3.14|     0.53|    9.7| normal|\n",
      "|          7.9|            0.18|       0.37|           1.2|     0.04|               16.0|                75.0|  0.992|3.18|     0.63|   10.8| normal|\n",
      "|          6.6|            0.16|        0.4|           1.5|    0.044|               48.0|               143.0| 0.9912|3.54|     0.52|   12.4|   good|\n",
      "|          8.3|            0.42|       0.62|         19.25|     0.04|               41.0|               172.0| 1.0002|2.98|     0.67|    9.7| normal|\n",
      "|          6.6|            0.17|       0.38|           1.5|    0.032|               28.0|               112.0| 0.9914|3.25|     0.55|   11.4|   good|\n",
      "|          6.3|            0.48|       0.04|           1.1|    0.046|               30.0|                99.0| 0.9928|3.24|     0.36|    9.6|   good|\n",
      "|          6.2|            0.66|       0.48|           1.2|    0.029|               29.0|                75.0| 0.9892|3.33|     0.39|   12.8|   good|\n",
      "|          7.4|            0.34|       0.42|           1.1|    0.033|               17.0|               171.0| 0.9917|3.12|     0.53|   11.3|   good|\n",
      "|          6.5|            0.31|       0.14|           7.5|    0.044|               34.0|               133.0| 0.9955|3.22|      0.5|    9.5| normal|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transf = df.withColumn(\"quality\", create_quality_groups(\"quality\"))\n",
    "df_transf.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8e115-9797-490f-a49a-5b577b492b6b",
   "metadata": {},
   "source": [
    "## 5. Model Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f15d40-f150-4ade-a1d4-2e87c974420b",
   "metadata": {},
   "source": [
    "<b>Multinomial logistic regression</b> is a type of logistic regression that can be used for multi-class classification problems. In the case of wine quality classification, there are 4 classes (poor, normal, good and excelent) so multinomial logistic regression is a good choice for modeling this problem.\n",
    "\n",
    "The physicochemical tests can be used to measure the various properties of wine, such as acidity, alcohol content, and sugar content. These properties can then be used as features in the multinomial logistic regression model.\n",
    "\n",
    "Here are some of the advantages of using multinomial logistic regression for wine quality classification:\n",
    "\n",
    "- It is a relatively simple model that is easy to understand and interpret.\n",
    "- It is a very flexible model that can be used to model a variety of different types of data.\n",
    "- It is a very efficient model that can be estimated quickly and easily.\n",
    "\n",
    "Here is some of the disadvantages of using multinomial logistic regression for wine quality classification:\n",
    "\n",
    "- It may not be as accurate as some other models, such as support vector machines or decision trees.\n",
    "- It may not be able to capture the nonlinear relationships between the features and the class labels.\n",
    "\n",
    "In addition to multinomial logistic regression, there are a number of other models that could be used for wine quality classification. Some of these other models include support vector machines, decision trees, and random forests. However, multinomial logistic regression is a good starting point for wine quality classification because it is a simple, flexible, and efficient model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5a896-ebf7-41d1-9087-ed0e99e2161d",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec542669-b32b-4874-bdc9-b88dc799da1c",
   "metadata": {},
   "source": [
    "### Split data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6143644-a1ce-4cc5-aa53-5f80975ec77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test data\n",
    "training, test = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee046b1-7b0a-4d69-8529-48270b99f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training instances 3929 test instances 969\n"
     ]
    }
   ],
   "source": [
    "print (\"training instances\", training.count(), \"test instances\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c88684-5447-4704-96c5-fb4487b02f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[3.8,0.31,0.02,11...|    6|\n",
      "|[4.2,0.17,0.36,1....|    7|\n",
      "|[4.2,0.215,0.23,5...|    3|\n",
      "|[4.4,0.32,0.39,4....|    8|\n",
      "|[4.4,0.46,0.1,2.8...|    6|\n",
      "|[4.5,0.19,0.21,0....|    5|\n",
      "|[4.6,0.445,0.0,1....|    5|\n",
      "|[4.7,0.145,0.29,1...|    6|\n",
      "|[4.7,0.335,0.14,1...|    5|\n",
      "|[4.7,0.455,0.18,1...|    7|\n",
      "|[4.7,0.67,0.09,1....|    5|\n",
      "|[4.7,0.785,0.0,3....|    6|\n",
      "|[4.8,0.13,0.32,1....|    7|\n",
      "|[4.8,0.17,0.28,2....|    7|\n",
      "|[4.8,0.21,0.21,10...|    7|\n",
      "|[4.8,0.225,0.38,1...|    6|\n",
      "|[4.8,0.26,0.23,10...|    7|\n",
      "|[4.8,0.29,0.23,1....|    6|\n",
      "|[4.8,0.33,0.0,6.5...|    5|\n",
      "|[4.8,0.34,0.0,6.5...|    6|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "training_data=training.rdd.map(lambda x:(Vectors.dense(x[0:-1]), x[-1])).toDF([\"features\", \"label\"])\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef44604-5006-424a-afb4-09c8b8cceb4e",
   "metadata": {},
   "source": [
    "### Train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1359b31a-56b6-4cda-8005-f5cdf86532d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/16 02:07:19 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/06/16 02:07:20 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(regParam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, elasticNetParam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, family\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m lrModel \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print the coefficients and intercept for multinomial logistic regression\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficients: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(lrModel\u001b[38;5;241m.\u001b[39mcoefficientMatrix))\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:335\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m--> 335\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:332\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03mFits a Java model to the input dataset.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m    fitted Java model\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1033\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1033\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1200\u001b[0m, in \u001b[0;36mGatewayConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while sending\u001b[39m\u001b[38;5;124m\"\u001b[39m, e, proto\u001b[38;5;241m.\u001b[39mERROR_ON_SEND)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1201\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstartswith(proto\u001b[38;5;241m.\u001b[39mRETURN_MESSAGE):\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(regParam=0.3, elasticNetParam=0.1, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training_data)\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01713d7-4e24-493f-a56b-a76a7e31c473",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97723165-a6ba-4753-9230-3c108759917c",
   "metadata": {},
   "source": [
    "## 8. Prediction"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
