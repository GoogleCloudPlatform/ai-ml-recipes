{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a3c702-7ac8-4e14-a96d-a0957073e5e5",
   "metadata": {},
   "source": [
    "# Housing prices prediction from real estate assessments (Decision Tree Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26448294-60b5-4e2f-825d-a4562fbd545f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0c35d-4d2c-4841-8e39-b727ec480687",
   "metadata": {},
   "source": [
    "This notebook shows how to predict housing prices (real estate assessed values) based on location and other characteristics using Decision Tree Regression.\n",
    "\n",
    "#### **Steps**\n",
    "Using Spark, \n",
    "1) It reads the table [Real Estate Sales](https://catalog.data.gov/dataset/real-estate-sales-2001-2018) from the **public_datasets** dataset located in the [metastore](../gcp_services/README.md) (notebook should be connected with the public metastore if using this specific dataset).  \n",
    "   This table contains listing of real estate sales with a sales price of $2,000 or greater that occur between October 1 and September 30 of each year (2001 to 2020).  \n",
    "   For each sale record, the file includes information such as town, property address, date of sale, property type (residential, apartment, commercial, industrial or vacant land), sales price, and property assessment.    \n",
    "2) It parses process the dataset to choose features and train the ML model (fits the decision tree regression model) to predict a target value.  \n",
    "3) It evaluates and plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709edcbd-6dd7-4df1-8068-f75b907ee9c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497dba8-0bdd-4314-a328-01e0bdc0c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import round, desc, corr, col\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import Bucketizer, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49eedf-6ef6-40f4-95fc-b0f9d00d4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f06c4-6687-43bd-90b6-b57a58816f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Housing prices prediction with Decision Tree Regression\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952801d6-8bbc-48f0-a6af-18f547df0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = spark.read.table(\"public_datasets.real_estate_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81c456-31b2-4343-8d59-bbcead8ae282",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pre-process dataset / filter values to increase quality of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a8bb8-2504-48ad-abd3-68af72778b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Filters\n",
    "filters = [\n",
    "\"opm_remarks IS NOT NULL AND opm_remarks != 'Unknown'\",\n",
    "\"non_use_code IS NOT NULL AND non_use_code != 'Unknown'\",\n",
    "\"assessor_remarks IS NOT NULL AND assessor_remarks != 'Unknown'\",\n",
    "\"residential_type IS NOT NULL AND residential_type != 'Unknown'\",\n",
    "\"property_type IS NOT NULL AND property_type != 'Unknown'\",\n",
    "\"assessed_value IS NOT NULL\",\n",
    "\"sale_amount IS NOT NULL\"\n",
    "]\n",
    "filters = \" AND \".join(filters)\n",
    "filtered_dataset = raw_dataset.filter(filters)\n",
    "\n",
    "#### Get only data from top towns\n",
    "top_towns = filtered_dataset.groupBy(\"town\").count().orderBy(desc(\"count\")).limit(30)\n",
    "towns_list = top_towns.select(\"town\").collect()\n",
    "towns_list = [town[0] for town in towns_list]\n",
    "filtered_dataset = filtered_dataset.filter(col(\"town\").isin(towns_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141be30-0f6f-496e-bb8a-f22aa9e8c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Filter assessed_value outliers\n",
    "def get_ranges(df, column_name, num_ranges=10):\n",
    "    min_value = df.agg({column_name: 'min' }).collect()[0][0]\n",
    "    max_value = df.agg({column_name: 'max' }).collect()[0][0]\n",
    "    ranges = []\n",
    "    ranges.append(min_value)\n",
    "    for i in range(num_ranges):\n",
    "        end = min_value + ((i + 1) * (max_value - min_value) / num_ranges)\n",
    "        ranges.append(end)\n",
    "    return ranges\n",
    "\n",
    "ranges = get_ranges(filtered_dataset, \"assessed_value\", num_ranges=10)\n",
    "bucketizer = Bucketizer(splits=ranges, inputCol=\"assessed_value\", outputCol=\"assessed_value_ranges_index\")\n",
    "with_split = bucketizer.transform(filtered_dataset)\n",
    "range_count = with_split.groupBy(\"assessed_value_ranges_index\").count()\n",
    "\n",
    "print(\"Range list: \", ranges)\n",
    "range_count.show()\n",
    "\n",
    "filtered_dataset = with_split.filter(\"assessed_value_ranges_index == 0\")\n",
    "\n",
    "filtered_dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e1600-69b9-44de-8b5c-66dcf80155df",
   "metadata": {},
   "source": [
    " serial_number|list_year|date_recorded|   town|             address|assessed_value|sale_amount|sales_ratio|property_type|residential_type|        non_use_code|    assessor_remarks|         opm_remarks|            location|\n",
    "|-------------|---------|-------------|-------|--------------------|--------------|-----------|-----------|-------------|----------------|--------------------|--------------------|--------------------|--------------------|\n",
    "|       200594|     2020|   2021-02-16|Danbury|        8 HICKORY ST|      121600.0|   146216.0|  0.8316463|  Residential|   Single Family|          25 - Other|              I11192|HOUSE HAS SETTLED...|{-73.44696, 41.41...|\n",
    "|       200562|     2020|   2021-02-03|Danbury|         19  MILL RD|      263600.0|   415000.0|  0.6351807|  Residential|   Single Family|          25 - Other|AFFORDABLE HOUSIN...|INCORRECT DATA PE...|{-73.53692, 41.38...|\n",
    "|       200968|     2020|   2021-05-24|Danbury|    4A FLIRTATION DR|      205700.0|   515000.0|  0.3994175|  Residential|   Single Family|07 - Change in Pr...|              B17008|UPDATED KITCHEN P...|        {null, null}|\n",
    "|       200260|     2020|   2020-11-23|Danbury|32 COALPIT HILL R...|       84900.0|   181778.0|  0.4670532|  Residential|           Condo|          25 - Other|            J16087-4|  MULTIPLE UNIT SALE|{-73.43796, 41.38...|\n",
    "|       200262|     2020|   2020-11-23|Danbury|32 COALPIT HILL R...|       84900.0|   181778.0|  0.4670532|  Residential|           Condo|          25 - Other|            J16087-6|  MULTIPLE UNIT SALE|{-73.43796, 41.38...|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db224407-fae7-4f2f-8828-27e8439b37e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde42868-baaf-4fe9-80c1-c4fc807c7e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count, Mean, Min, Max of numeric columns\n",
    "numeric_columns = [\"list_year\",\"assessed_value\",\"sale_amount\"]\n",
    "filtered_dataset.select(numeric_columns).describe().select('summary', *[round(c, 2).alias(c) for c in numeric_columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f8943-b52e-4d9e-9c2e-b79c2345025d",
   "metadata": {},
   "source": [
    "|summary|list_year|assessed_value|sale_amount|\n",
    "|-------|---------|--------------|-----------|\n",
    "|  count|    755.0|         755.0|      755.0|\n",
    "|   mean|   2017.9|     132269.29|  212040.05|\n",
    "| stddev|     1.37|      69455.55|   273021.1|\n",
    "|    min|   2009.0|        6650.0|     1500.0|\n",
    "|    max|   2020.0|      337630.0|  3000000.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10093e-2ff2-41ee-91c6-b3ed30a0d5f2",
   "metadata": {},
   "source": [
    "Here we choose to use the \"assessed_value\" as prediction target instead of the \"sale_amount\" due to the higher standard deviation of the sale_amount value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc12f0-ab19-42a4-af6c-3faef821f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Towns\n",
    "filtered_dataset.groupBy(\"town\").count().orderBy(desc(\"count\")).limit(10).show(10,100)\n",
    "print(f'Number of distinct towns: {filtered_dataset.select(\"town\").distinct().count()}')\n",
    "print(f'Number of towns: {filtered_dataset.select(\"town\").count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105da30-4944-40bc-b56c-60ea648a29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property Type\n",
    "filtered_dataset.groupBy(\"property_type\").count().orderBy(desc(\"count\")).limit(12).show(12,100)\n",
    "print(f'Number of property type: {filtered_dataset.select(\"property_type\").count()}')\n",
    "print(f'Number of distinct property type: {filtered_dataset.select(\"property_type\").distinct().count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583e5e3-e0d0-4ff7-8019-39a0eeb6a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residential Type\n",
    "filtered_dataset.groupBy(\"residential_type\").count().orderBy(desc(\"count\")).limit(12).show(12,100)\n",
    "print(f'Number of residential type: {filtered_dataset.select(\"residential_type\").count()}')\n",
    "print(f'Number of distinct residential type: {filtered_dataset.select(\"residential_type\").distinct().count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b6095-ce30-4358-82dd-bf2e0f781ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years\n",
    "filtered_dataset.groupBy(\"list_year\").count().orderBy(desc(\"count\")).limit(10).show(10,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79916aa6-0628-4dc2-92c0-dea658c07ba9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process dataset to create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f643a32-5ad9-4c37-8e52-4e3303fce782",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['assessed_value','town','list_year','property_type','residential_type']\n",
    "label_column = 'assessed_value'\n",
    "categorical_columns = ['town','list_year','property_type','residential_type']\n",
    "feature_columns = ['indexed_town','indexed_list_year','indexed_property_type','indexed_residential_type']\n",
    "\n",
    "#### Select only some columns\n",
    "sub_dataset = filtered_dataset.select(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414bd29-03a5-40dd-8771-eadc59f2b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de2bc5-ebe9-46da-9a7d-22c98f44babb",
   "metadata": {},
   "source": [
    "|assessed_value|    town|list_year|property_type|residential_type|\n",
    "|--------------|--------|---------|-------------|----------------|\n",
    "|      108430.0|Griswold|     2020|  Residential|      Two Family|\n",
    "|      121600.0| Danbury|     2020|  Residential|   Single Family|\n",
    "|      263600.0| Danbury|     2020|  Residential|   Single Family|\n",
    "|      205700.0| Danbury|     2020|  Residential|   Single Family|\n",
    "|       84900.0| Danbury|     2020|  Residential|           Condo|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8046b-8478-4fa8-bd99-23e44daad694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Index categorical columns\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=\"indexed_\" + column).fit(sub_dataset) for column in categorical_columns]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_dataset = pipeline.fit(sub_dataset).transform(sub_dataset)\n",
    "indexed_dataset = indexed_dataset.drop(*categorical_columns)\n",
    "indexed_dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96398b0-79a9-4e05-aba9-5eddf7fafd2e",
   "metadata": {},
   "source": [
    "|assessed_value|indexed_town|indexed_list_year|indexed_property_type|indexed_residential_type|\n",
    "|--------------|------------|-----------------|---------------------|------------------------|\n",
    "|      108430.0|        13.0|              3.0|                  2.0|                     2.0|\n",
    "|      121600.0|         0.0|              3.0|                  2.0|                     0.0|\n",
    "|      263600.0|         0.0|              3.0|                  2.0|                     0.0|\n",
    "|      205700.0|         0.0|              3.0|                  2.0|                     0.0|\n",
    "|       84900.0|         0.0|              3.0|                  2.0|                     1.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463e7e4-5059-4b48-a8be-a7b72471e0d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform features to LIBSVM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c368ca7-647c-442d-b98b-331704814af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "dataset = assembler.transform(indexed_dataset)\n",
    "\n",
    "dataset = dataset.select(label_column,'features')\n",
    "dataset = dataset.withColumnRenamed(label_column,'label')\n",
    "\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06a6f9-20b9-475b-ab27-6fa2f9d2c2cb",
   "metadata": {},
   "source": [
    "|   label|          features|\n",
    "|--------|------------------|\n",
    "|108430.0|[13.0,3.0,2.0,2.0]|\n",
    "|121600.0| [0.0,3.0,2.0,0.0]|\n",
    "|263600.0| [0.0,3.0,2.0,0.0]|\n",
    "|205700.0| [0.0,3.0,2.0,0.0]|\n",
    "| 84900.0| [0.0,3.0,2.0,1.0]|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2fa39-94b5-4b64-bd1e-d566aeced15a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train/Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9422291-4215-4c9c-8375-5fa6a34cca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3])\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", maxDepth = 25, maxBins = 60)\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[dt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b94b0-855f-4ae4-8a50-80a812cd2f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e864dc-a503-43e9-b05d-716260825183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(10)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15fc83-0097-460e-a6f7-563fdcd2b91c",
   "metadata": {},
   "source": [
    "|        prediction|  label|          features|\n",
    "|------------------|-------|------------------|\n",
    "|           40090.0|46840.0| [6.0,3.0,2.0,1.0]|\n",
    "| 87633.33333333333|59500.0| [0.0,3.0,2.0,1.0]|\n",
    "|108368.33333333333|78540.0|[15.0,3.0,2.0,0.0]|\n",
    "| 87633.33333333333|84900.0| [0.0,3.0,2.0,1.0]|\n",
    "| 87633.33333333333|87000.0| [0.0,3.0,2.0,1.0]|\n",
    "|          123465.0|98730.0| [6.0,3.0,2.0,0.0]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0c11d-be3d-4422-9c08-ac3fcc81f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Count, Mean, Min, Max of predictions\n",
    "predictions.select([\"prediction\", \"label\"]).describe().select('summary', *[round(c, 2).alias(c) for c in [\"prediction\", \"label\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f91cf-528e-44e5-b922-573e394e3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model results\n",
    "treeModel = model.stages[0]\n",
    "print(treeModel)\n",
    "print(treeModel.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fff284-81a0-40c5-adfd-f06fed688bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot predictions against target\n",
    "x = range(0, predictions.count())\n",
    "y_pred=predictions.select(\"prediction\").collect()\n",
    "y_target=predictions.select(\"label\").collect()\n",
    " \n",
    "plt.plot(x, y_target, label=\"label\")\n",
    "plt.plot(x, y_pred, label=\"prediction\")\n",
    "plt.title(\"Test and predicted data\")\n",
    "\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "\n",
    "plt.legend(loc='best',fancybox=True, shadow=False)\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
