{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Generate descriptions from videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to generate descriptions of videos in a GCS bucket.  \n",
    "It uses the [Youtube UGC dataset](https://media.withyoutube.com/) and uses the [Gemini](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini) to generate video descriptions for each video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### **Steps**\n",
    "Using Spark,\n",
    "1) It reads a metadata table of the [Youtube UGC dataset](https://media.withyoutube.com/) from the **public_datasets** dataset located in the [metastore](../../public_datasets/dataproc_metastore/metastore_public_datasets_quickstart.ipynb) (notebook should be connected with the public metastore if using this specific dataset).\n",
    "This metadata table contains the paths of the image files in the bucket.\n",
    "If you want to apply this to a different dataset, you can read the pdf files in your bucket with spark.read.format(\"binaryFile\") (no need of the metastore) - more details [here](../../public_datasets/dataproc_metastore/metastore_public_datasets_quickstart.ipynb).\n",
    "2) It calls Vertex AI Gemini API to get product sales descriptions based on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Make sure the service account running this notebook has the required permissions:\n",
    "\n",
    "- **Run the notebook**\n",
    "  - AI Platform Notebooks Service Agent\n",
    "  - Notebooks Admin\n",
    "  - Vertex AI Administrator\n",
    "- **Read tables from Dataproc Metastore**\n",
    "  - Dataproc Metastore Editor\n",
    "  - Dataproc Metastore Metadata Editor\n",
    "  - Dataproc Metastore Metadata User\n",
    "  - Dataproc Metastore Service Agent\n",
    "- **Read files from bucket**\n",
    "  - Storage Object Viewer\n",
    "- **Run Dataproc jobs**\n",
    "  - Dataproc Service Agent\n",
    "  - Dataproc Worker\n",
    "- **Call Google APIs**\n",
    "  - Service Usage Consumer\n",
    "- **BigQuery**\n",
    "  - BigQuery Data Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, concat\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.min_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/08 19:06:44 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"Video descriptions generation\") \\\n",
    "  .enableHiveSupport() \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Read the dataset from the public Dataproc Metastore connected\n",
    "# binaries_df = spark.read.table(\"public_datasets.youtube_ucg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Another option is to read from the bucket directly\n",
    "BINARIES_BUCKET_PATH = \"gs://dataproc-metastore-public-binaries/youtube_ucg/\"\n",
    "binaries_df = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").load(BINARIES_BUCKET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------------------+\n",
      "|                path|    modificationTime| length|             content|\n",
      "+--------------------+--------------------+-------+--------------------+\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|5051568|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|4450939|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|2766749|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|2525019|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|2311945|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|1682359|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|1389832|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|1388558|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|1095245|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|1020169|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 957007|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 892494|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 877287|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 737776|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 666720|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 411959|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 306282|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 227457|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...| 188195|[00 00 00 20 66 7...|\n",
      "|gs://dataproc-met...|2024-01-04 20:08:...|  57054|[00 00 00 20 66 7...|\n",
      "+--------------------+--------------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaries_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's select the paths of the first 100 product images\n",
    "paths_df = binaries_df.select(\"path\").limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                path|\n",
      "+--------------------+\n",
      "|gs://dataproc-met...|\n",
      "|gs://dataproc-met...|\n",
      "|gs://dataproc-met...|\n",
      "|gs://dataproc-met...|\n",
      "|gs://dataproc-met...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paths_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define UDF and call Gemini API to generate video descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_descriptions(gcs_uri):\n",
    "\n",
    "  def gemini_predict(gcs_uri, prompt):\n",
    "      \n",
    "    model_url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{project_id}/locations/us-central1/publishers/google/models/gemini-pro-vision:streamGenerateContent\"\n",
    "    request_body = {\n",
    "      \"contents\": {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          {\n",
    "            \"fileData\": {\n",
    "              \"mimeType\": \"video/mp4\",\n",
    "              \"fileUri\": gcs_uri\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"text\": prompt\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"safety_settings\": {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "      },\n",
    "      \"generation_config\": {\n",
    "        \"temperature\": 0.4,\n",
    "        \"topP\": 1.0,\n",
    "        \"topK\": 32,\n",
    "        \"maxOutputTokens\": 2048\n",
    "      }\n",
    "    }\n",
    "      \n",
    "    prediction = requests.post(\n",
    "      model_url,\n",
    "      headers={'Authorization': 'Bearer %s' % credentials.token,\n",
    "               'Content-Type': 'application/json'},\n",
    "      json = request_body\n",
    "    ).json()\n",
    "\n",
    "\n",
    "    full_prediction = \"\"\n",
    "    for pred in prediction:\n",
    "      if \"candidates\" in pred:\n",
    "        content = pred[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        full_prediction += content\n",
    "    return full_prediction\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "        Create a short description for this video with the following questions:\n",
    "         1-) Where the video was from? \n",
    "         2-) How many people we have? \n",
    "         3-) What pople are doing? \n",
    "         4-) whats the proposition for the video?\n",
    "         5-) A sumary description from the itens 1,2,3 and 4\n",
    "        Format the 5 descriptions in a JSON format with the KEYS: Where, HowManyPeople, Task, Proposition and Description.\n",
    "    \"\"\"\n",
    "\n",
    "  descriptions = gemini_predict(gcs_uri, prompt)\n",
    "\n",
    "  return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generate_descriptions_udf = udf(generate_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_descriptions = paths_df.sort(paths_df.path.asc()).withColumn(\"data\", generate_descriptions_udf(paths_df.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, data: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descriptions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"The video was recorded in a park.\",\\n        \"HowManyPeople\": \"There are two people in the video.\",\\n        \"Task\": \"The people are playing with a dog.\",\\n        \"Proposition\": \"The video is about two people playing with a dog in a park.\",\\n        \"Description\": \"The video is about two people playing with a dog in a park. The people are throwing a ball for the dog to fetch. The dog is running around and having fun. The people are laughing and enjoying themselves. The video is short and sweet, and it captures the joy of playing with a dog.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-1dba.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"From a table at home\",\\n        \"HowManyPeople\": \"One person\",\\n        \"Task\": \"Making a rainbow loom bracelet\",\\n        \"Proposition\": \"This video shows you how to make a rainbow loom bracelet.\",\\n        \"Description\": \"A person is sitting at a table making a rainbow loom bracelet. The person is wearing a blue sweatshirt. The table is made of wood and is stained a dark brown color.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"From a notebook.\",\\n        \"HowManyPeople\": \"One person.\",\\n        \"Task\": \"The person is drawing.\",\\n        \"Proposition\": \"The video is about drawing.\",\\n        \"Description\": \"A person is drawing in a notebook.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-5da7.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"The video was taken from a person's home.\",\\n        \"HowManyPeople\": \"There is one person in the video.\",\\n        \"Task\": \"The person is using a hot glue gun to create a design on a surface.\",\\n        \"Proposition\": \"The video is about how to use a hot glue gun to create a design on a surface.\",\\n        \"Description\": \"The video shows a person using a hot glue gun to create a design on a surface. The person is skilled in using the hot glue gun and is able to create a beautiful design. The video is informative and easy to follow.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"From a couch in a living room.\",\\n        \"HowManyPeople\": \"There is one person in the video.\",\\n        \"Task\": \"The person is drawing a picture.\",\\n        \"Proposition\": \"The video is about drawing a picture.\",\\n        \"Description\": \"A person is sitting on a couch in a living room, drawing a picture. The person is wearing glasses and has short brown hair. They are using a pencil and a piece of paper. The picture is of a anime character.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "0  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4   \n",
       "1  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-1dba.mp4   \n",
       "2  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4   \n",
       "3  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-5da7.mp4   \n",
       "4  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              data  \n",
       "0   ```json\\n        {\\n        \"Where\": \"The video was recorded in a park.\",\\n        \"HowManyPeople\": \"There are two people in the video.\",\\n        \"Task\": \"The people are playing with a dog.\",\\n        \"Proposition\": \"The video is about two people playing with a dog in a park.\",\\n        \"Description\": \"The video is about two people playing with a dog in a park. The people are throwing a ball for the dog to fetch. The dog is running around and having fun. The people are laughing and enjoying themselves. The video is short and sweet, and it captures the joy of playing with a dog.\"\\n        }\\n    ```  \n",
       "1                                                                                                                                                                  ```json\\n        {\\n        \"Where\": \"From a table at home\",\\n        \"HowManyPeople\": \"One person\",\\n        \"Task\": \"Making a rainbow loom bracelet\",\\n        \"Proposition\": \"This video shows you how to make a rainbow loom bracelet.\",\\n        \"Description\": \"A person is sitting at a table making a rainbow loom bracelet. The person is wearing a blue sweatshirt. The table is made of wood and is stained a dark brown color.\"\\n        }\\n    ```  \n",
       "2                                                                                                                                                                                                                                                                                                                                             ```json\\n        {\\n        \"Where\": \"From a notebook.\",\\n        \"HowManyPeople\": \"One person.\",\\n        \"Task\": \"The person is drawing.\",\\n        \"Proposition\": \"The video is about drawing.\",\\n        \"Description\": \"A person is drawing in a notebook.\"\\n        }\\n    ```  \n",
       "3            ```json\\n        {\\n        \"Where\": \"The video was taken from a person's home.\",\\n        \"HowManyPeople\": \"There is one person in the video.\",\\n        \"Task\": \"The person is using a hot glue gun to create a design on a surface.\",\\n        \"Proposition\": \"The video is about how to use a hot glue gun to create a design on a surface.\",\\n        \"Description\": \"The video shows a person using a hot glue gun to create a design on a surface. The person is skilled in using the hot glue gun and is able to create a beautiful design. The video is informative and easy to follow.\"\\n        }\\n    ```  \n",
       "4                                                                                                         ```json\\n        {\\n        \"Where\": \"From a couch in a living room.\",\\n        \"HowManyPeople\": \"There is one person in the video.\",\\n        \"Task\": \"The person is drawing a picture.\",\\n        \"Proposition\": \"The video is about drawing a picture.\",\\n        \"Description\": \"A person is sitting on a couch in a living room, drawing a picture. The person is wearing glasses and has short brown hair. They are using a pencil and a piece of paper. The picture is of a anime character.\"\\n        }\\n    ```  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descriptions.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract feature from generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('Where', StringType(), True),\n",
    "        StructField('HowManyPeople', StringType(), True),\n",
    "        StructField('Proposition', StringType(), True),\n",
    "        StructField('Description', StringType(), True),\n",
    "        StructField('Task', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "df_final = df_descriptions.withColumn(\"data2\", from_json(regexp_replace(regexp_replace(col(\"data\"),\"json\", \"\"),\"```\",\"\"), schema))\\\n",
    "    .select(col('path'),col('data2.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Where</th>\n",
       "      <th>HowManyPeople</th>\n",
       "      <th>Proposition</th>\n",
       "      <th>Description</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4</td>\n",
       "      <td>The video was recorded in a park.</td>\n",
       "      <td>There are two people in the video.</td>\n",
       "      <td>The video is about two people playing with a dog in a park.</td>\n",
       "      <td>The video is about two people playing with a dog in a park. The people are throwing a ball for the dog to fetch. The dog is running around and having fun. The people are laughing and enjoying themselves. The video is short and sweet, and it captures the joy of playing with a dog.</td>\n",
       "      <td>The people are playing with a dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-1dba.mp4</td>\n",
       "      <td>From a table at home</td>\n",
       "      <td>One person</td>\n",
       "      <td>This video shows you how to make a rainbow loom bracelet.</td>\n",
       "      <td>A person is sitting at a table making a rainbow loom bracelet. The person is wearing a blue sweatshirt. The table is made of wood and is stained a dark brown color.</td>\n",
       "      <td>Making a rainbow loom bracelet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4</td>\n",
       "      <td>From a notebook.</td>\n",
       "      <td>One person.</td>\n",
       "      <td>The video is about drawing.</td>\n",
       "      <td>A person is drawing in a notebook.</td>\n",
       "      <td>The person is drawing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-5da7.mp4</td>\n",
       "      <td>The video was taken from a person's home.</td>\n",
       "      <td>There is one person in the video.</td>\n",
       "      <td>The video is about how to use a hot glue gun to create a design on a surface.</td>\n",
       "      <td>The video shows a person using a hot glue gun to create a design on a surface. The person is skilled in using the hot glue gun and is able to create a beautiful design. The video is informative and easy to follow.</td>\n",
       "      <td>The person is using a hot glue gun to create a design on a surface.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4</td>\n",
       "      <td>From a couch in a living room.</td>\n",
       "      <td>There is one person in the video.</td>\n",
       "      <td>The video is about drawing a picture.</td>\n",
       "      <td>A person is sitting on a couch in a living room, drawing a picture. The person is wearing glasses and has short brown hair. They are using a pencil and a piece of paper. The picture is of a anime character.</td>\n",
       "      <td>The person is drawing a picture.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "0  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4   \n",
       "1  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-1dba.mp4   \n",
       "2  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4   \n",
       "3  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-5da7.mp4   \n",
       "4  gs://dataproc-metastore-public-binaries/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4   \n",
       "\n",
       "                                       Where  \\\n",
       "0          The video was recorded in a park.   \n",
       "1                       From a table at home   \n",
       "2                           From a notebook.   \n",
       "3  The video was taken from a person's home.   \n",
       "4             From a couch in a living room.   \n",
       "\n",
       "                        HowManyPeople  \\\n",
       "0  There are two people in the video.   \n",
       "1                          One person   \n",
       "2                         One person.   \n",
       "3   There is one person in the video.   \n",
       "4   There is one person in the video.   \n",
       "\n",
       "                                                                     Proposition  \\\n",
       "0                    The video is about two people playing with a dog in a park.   \n",
       "1                      This video shows you how to make a rainbow loom bracelet.   \n",
       "2                                                    The video is about drawing.   \n",
       "3  The video is about how to use a hot glue gun to create a design on a surface.   \n",
       "4                                          The video is about drawing a picture.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                Description  \\\n",
       "0  The video is about two people playing with a dog in a park. The people are throwing a ball for the dog to fetch. The dog is running around and having fun. The people are laughing and enjoying themselves. The video is short and sweet, and it captures the joy of playing with a dog.   \n",
       "1                                                                                                                      A person is sitting at a table making a rainbow loom bracelet. The person is wearing a blue sweatshirt. The table is made of wood and is stained a dark brown color.   \n",
       "2                                                                                                                                                                                                                                                        A person is drawing in a notebook.   \n",
       "3                                                                     The video shows a person using a hot glue gun to create a design on a surface. The person is skilled in using the hot glue gun and is able to create a beautiful design. The video is informative and easy to follow.   \n",
       "4                                                                            A person is sitting on a couch in a living room, drawing a picture. The person is wearing glasses and has short brown hair. They are using a pencil and a piece of paper. The picture is of a anime character.   \n",
       "\n",
       "                                                                  Task  \n",
       "0                                   The people are playing with a dog.  \n",
       "1                                       Making a rainbow loom bracelet  \n",
       "2                                               The person is drawing.  \n",
       "3  The person is using a hot glue gun to create a design on a surface.  \n",
       "4                                     The person is drawing a picture.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teste4 on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-0000337f1964"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
