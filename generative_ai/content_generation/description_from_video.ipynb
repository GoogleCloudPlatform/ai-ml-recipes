{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Generate descriptions from videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to generate descriptions of videos in a GCS bucket.  \n",
    "It uses the [Youtube UGC dataset](https://media.withyoutube.com/) and uses the [Gemini](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini) to generate video descriptions for each video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### **Steps**\n",
    "Using Spark,\n",
    "1) It reads a metadata table of the [Youtube UGC dataset](https://media.withyoutube.com/) from the **public_datasets** dataset located in the [metastore](../../public_datasets/dataproc_metastore/metastore_public_datasets_quickstart.ipynb) (notebook should be connected with the public metastore if using this specific dataset).\n",
    "This metadata table contains the paths of the image files in the bucket.\n",
    "If you want to apply this to a different dataset, you can read the pdf files in your bucket with spark.read.format(\"binaryFile\") (no need of the metastore) - more details [here](../../public_datasets/dataproc_metastore/metastore_public_datasets_quickstart.ipynb).\n",
    "2) It calls Vertex AI Gemini API to get product sales descriptions based on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Make sure the service account running this notebook has the required permissions:\n",
    "\n",
    "- **Run the notebook**\n",
    "  - AI Platform Notebooks Service Agent\n",
    "  - Notebooks Admin\n",
    "  - Vertex AI Administrator\n",
    "- **Read tables from Dataproc Metastore**\n",
    "  - Dataproc Metastore Editor\n",
    "  - Dataproc Metastore Metadata Editor\n",
    "  - Dataproc Metastore Metadata User\n",
    "  - Dataproc Metastore Service Agent\n",
    "- **Read files from bucket**\n",
    "  - Storage Object Viewer\n",
    "- **Run Dataproc jobs**\n",
    "  - Dataproc Service Agent\n",
    "  - Dataproc Worker\n",
    "- **Call Google APIs**\n",
    "  - Service Usage Consumer\n",
    "- **BigQuery**\n",
    "  - BigQuery Data Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, concat\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.min_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/04 14:58:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"Video descriptions generation\") \\\n",
    "  .enableHiveSupport() \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Read the dataset from the public Dataproc Metastore connected\n",
    "binaries_df = spark.read.table(\"public_datasets.youtube_ucg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Another option is to read from the bucket directly\n",
    "# BINARIES_BUCKET_PATH = \"gs://dataproc-metastore-public-binaries/stanford_online_products/\"\n",
    "# binaries_df = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").load(BINARIES_BUCKET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's select the paths of the first 100 product images\n",
    "paths_df = binaries_df.select(\"path\").limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                path|\n",
      "+--------------------+\n",
      "|gs://diogokato-us...|\n",
      "|gs://diogokato-us...|\n",
      "|gs://diogokato-us...|\n",
      "|gs://diogokato-us...|\n",
      "|gs://diogokato-us...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paths_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define UDF and call Gemini API to generate video descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_descriptions(gcs_uri):\n",
    "\n",
    "  def gemini_predict(gcs_uri, prompt):\n",
    "      \n",
    "    model_url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{project_id}/locations/us-central1/publishers/google/models/gemini-pro-vision:streamGenerateContent\"\n",
    "    request_body = {\n",
    "      \"contents\": {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          {\n",
    "            \"fileData\": {\n",
    "              \"mimeType\": \"video/mp4\",\n",
    "              \"fileUri\": gcs_uri\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"text\": prompt\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"safety_settings\": {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "      },\n",
    "      \"generation_config\": {\n",
    "        \"temperature\": 0.4,\n",
    "        \"topP\": 1.0,\n",
    "        \"topK\": 32,\n",
    "        \"maxOutputTokens\": 2048\n",
    "      }\n",
    "    }\n",
    "      \n",
    "    prediction = requests.post(\n",
    "      model_url,\n",
    "      headers={'Authorization': 'Bearer %s' % credentials.token,\n",
    "               'Content-Type': 'application/json'},\n",
    "      json = request_body\n",
    "    ).json()\n",
    "\n",
    "\n",
    "    full_prediction = \"\"\n",
    "    for pred in prediction:\n",
    "      if \"candidates\" in pred:\n",
    "        content = pred[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        full_prediction += content\n",
    "    return full_prediction\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "        Create a short description for this video with the following questions:\n",
    "         1-) Where the video was from? \n",
    "         2-) How many people we have? \n",
    "         3-) What pople are doing? \n",
    "         4-) whats the proposition for the video?\n",
    "         5-) A sumary description from the itens 1,2,3 and 4\n",
    "        Format the 5 descriptions in a JSON format with the KEYS: Where, HowManyPeople, Task, Proposition and Description.\n",
    "    \"\"\"\n",
    "\n",
    "  descriptions = gemini_predict(gcs_uri, prompt)\n",
    "\n",
    "  return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generate_descriptions_udf = udf(generate_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_descriptions = paths_df.sort(paths_df.path.asc()).withColumn(\"data\", generate_descriptions_udf(paths_df.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, data: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descriptions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"From a phone\",\\n        \"HowManyPeople\": \"One person\",\\n        \"Task\": \"Showing how to delete a folder\",\\n        \"Proposition\": \"If you want to delete a folder, you can do it by following the steps in this video\",\\n        \"Description\": \"The video shows how to delete a folder on a phone. The video is from a phone, and it shows one person deleting a folder. The video is short and easy to follow, and it provides clear instructions on how to delete a folder.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2074.mp4</td>\n",
       "      <td>```json\\n{\\n  \"Where\": \"The video was taken from a home.\",\\n  \"HowManyPeople\": \"There is one person in the video.\",\\n  \"Task\": \"The person is cutting out felt petals from a larger piece of felt.\",\\n  \"Proposition\": \"The video is about how to make felt petals.\",\\n  \"Description\": \"A person is cutting out felt petals from a larger piece of felt. The video is about how to make felt petals.\"\\n}\\n```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"A classroom\",\\n        \"HowManyPeople\": \"One\",\\n        \"Task\": \"Writing on a notebook\",\\n        \"Proposition\": \"To show how to write on a notebook\",\\n        \"Description\": \"A person is writing on a notebook. The person is using a pencil. The person is writing in cursive. The person is writing a sentence. The sentence is 'I am writing on a notebook'.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-6a0e.mp4</td>\n",
       "      <td>```json\\n{\\n  \"Where\": \"From a forest\",\\n  \"HowManyPeople\": \"There aren't people\",\\n  \"Task\": \"Showing an image processing\",\\n  \"Proposition\": \"The video shows how to process an image using a high pass filter to enhance the details.\",\\n  \"Description\": \"The video shows how to process an image using a high pass filter to enhance the details. The video is from a forest, and there aren't people. The video shows how to use the high pass filter to enhance the details of the image.\"\\n}\\n```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4</td>\n",
       "      <td>```json\\n        {\\n        \"Where\": \"From a house\",\\n        \"HowManyPeople\": \"One person\",\\n        \"Task\": \"Drawing Sailor Moon\",\\n        \"Proposition\": \"Watch the video to see the drawing\",\\n        \"Description\": \"A person is drawing Sailor Moon. The person is sitting on a couch and has a lot of manga on the table.\"\\n        }\\n    ```</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           path  \\\n",
       "0  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4   \n",
       "1  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2074.mp4   \n",
       "2  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4   \n",
       "3  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-6a0e.mp4   \n",
       "4  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         data  \n",
       "0   ```json\\n        {\\n        \"Where\": \"From a phone\",\\n        \"HowManyPeople\": \"One person\",\\n        \"Task\": \"Showing how to delete a folder\",\\n        \"Proposition\": \"If you want to delete a folder, you can do it by following the steps in this video\",\\n        \"Description\": \"The video shows how to delete a folder on a phone. The video is from a phone, and it shows one person deleting a folder. The video is short and easy to follow, and it provides clear instructions on how to delete a folder.\"\\n        }\\n    ```  \n",
       "1                                                                                                                              ```json\\n{\\n  \"Where\": \"The video was taken from a home.\",\\n  \"HowManyPeople\": \"There is one person in the video.\",\\n  \"Task\": \"The person is cutting out felt petals from a larger piece of felt.\",\\n  \"Proposition\": \"The video is about how to make felt petals.\",\\n  \"Description\": \"A person is cutting out felt petals from a larger piece of felt. The video is about how to make felt petals.\"\\n}\\n```  \n",
       "2                                                                                                               ```json\\n        {\\n        \"Where\": \"A classroom\",\\n        \"HowManyPeople\": \"One\",\\n        \"Task\": \"Writing on a notebook\",\\n        \"Proposition\": \"To show how to write on a notebook\",\\n        \"Description\": \"A person is writing on a notebook. The person is using a pencil. The person is writing in cursive. The person is writing a sentence. The sentence is 'I am writing on a notebook'.\"\\n        }\\n    ```  \n",
       "3                                   ```json\\n{\\n  \"Where\": \"From a forest\",\\n  \"HowManyPeople\": \"There aren't people\",\\n  \"Task\": \"Showing an image processing\",\\n  \"Proposition\": \"The video shows how to process an image using a high pass filter to enhance the details.\",\\n  \"Description\": \"The video shows how to process an image using a high pass filter to enhance the details. The video is from a forest, and there aren't people. The video shows how to use the high pass filter to enhance the details of the image.\"\\n}\\n```  \n",
       "4                                                                                                                                                                                     ```json\\n        {\\n        \"Where\": \"From a house\",\\n        \"HowManyPeople\": \"One person\",\\n        \"Task\": \"Drawing Sailor Moon\",\\n        \"Proposition\": \"Watch the video to see the drawing\",\\n        \"Description\": \"A person is drawing Sailor Moon. The person is sitting on a couch and has a lot of manga on the table.\"\\n        }\\n    ```  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descriptions.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract feature from generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('Where', StringType(), True),\n",
    "        StructField('HowManyPeople', StringType(), True),\n",
    "        StructField('Proposition', StringType(), True),\n",
    "        StructField('Description', StringType(), True),\n",
    "        StructField('Task', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "df_final = df_descriptions.withColumn(\"data2\", from_json(regexp_replace(regexp_replace(col(\"data\"),\"json\", \"\"),\"```\",\"\"), schema))\\\n",
    "    .select(col('path'),col('data2.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Where</th>\n",
       "      <th>HowManyPeople</th>\n",
       "      <th>Proposition</th>\n",
       "      <th>Description</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4</td>\n",
       "      <td>From a phone</td>\n",
       "      <td>One person</td>\n",
       "      <td>If you want to delete a folder, you can do it by following the steps in this video</td>\n",
       "      <td>The video shows how to delete a folder on a phone. The video is from a phone, and it shows one person deleting a folder. The video is short and easy to follow, and it provides clear instructions on how to delete a folder.</td>\n",
       "      <td>Showing how to delete a folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2074.mp4</td>\n",
       "      <td>The video was taken from a home.</td>\n",
       "      <td>There is one person in the video.</td>\n",
       "      <td>The video is about how to make felt petals.</td>\n",
       "      <td>A person is cutting out felt petals from a larger piece of felt. The video is about how to make felt petals.</td>\n",
       "      <td>The person is cutting out felt petals from a larger piece of felt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4</td>\n",
       "      <td>A classroom</td>\n",
       "      <td>One</td>\n",
       "      <td>To show how to write on a notebook</td>\n",
       "      <td>A person is writing on a notebook. The person is using a pencil. The person is writing in cursive. The person is writing a sentence. The sentence is 'I am writing on a notebook'.</td>\n",
       "      <td>Writing on a notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-6a0e.mp4</td>\n",
       "      <td>From a forest</td>\n",
       "      <td>There aren't people</td>\n",
       "      <td>The video shows how to process an image using a high pass filter to enhance the details.</td>\n",
       "      <td>The video shows how to process an image using a high pass filter to enhance the details. The video is from a forest, and there aren't people. The video shows how to use the high pass filter to enhance the details of the image.</td>\n",
       "      <td>Showing an image processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4</td>\n",
       "      <td>From a house</td>\n",
       "      <td>One person</td>\n",
       "      <td>Watch the video to see the drawing</td>\n",
       "      <td>A person is drawing Sailor Moon. The person is sitting on a couch and has a lot of manga on the table.</td>\n",
       "      <td>Drawing Sailor Moon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           path  \\\n",
       "0  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-09f8.mp4   \n",
       "1  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2074.mp4   \n",
       "2  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-2fd5.mp4   \n",
       "3  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-6a0e.mp4   \n",
       "4  gs://diogokato-us/youtube_ucg/original_videos/HowTo/360P/HowTo_360P-7fb1.mp4   \n",
       "\n",
       "                              Where                      HowManyPeople  \\\n",
       "0                      From a phone                         One person   \n",
       "1  The video was taken from a home.  There is one person in the video.   \n",
       "2                       A classroom                                One   \n",
       "3                     From a forest                There aren't people   \n",
       "4                      From a house                         One person   \n",
       "\n",
       "                                                                                Proposition  \\\n",
       "0        If you want to delete a folder, you can do it by following the steps in this video   \n",
       "1                                               The video is about how to make felt petals.   \n",
       "2                                                        To show how to write on a notebook   \n",
       "3  The video shows how to process an image using a high pass filter to enhance the details.   \n",
       "4                                                        Watch the video to see the drawing   \n",
       "\n",
       "                                                                                                                                                                                                                          Description  \\\n",
       "0       The video shows how to delete a folder on a phone. The video is from a phone, and it shows one person deleting a folder. The video is short and easy to follow, and it provides clear instructions on how to delete a folder.   \n",
       "1                                                                                                                        A person is cutting out felt petals from a larger piece of felt. The video is about how to make felt petals.   \n",
       "2                                                  A person is writing on a notebook. The person is using a pencil. The person is writing in cursive. The person is writing a sentence. The sentence is 'I am writing on a notebook'.   \n",
       "3  The video shows how to process an image using a high pass filter to enhance the details. The video is from a forest, and there aren't people. The video shows how to use the high pass filter to enhance the details of the image.   \n",
       "4                                                                                                                              A person is drawing Sailor Moon. The person is sitting on a couch and has a lot of manga on the table.   \n",
       "\n",
       "                                                                 Task  \n",
       "0                                      Showing how to delete a folder  \n",
       "1  The person is cutting out felt petals from a larger piece of felt.  \n",
       "2                                               Writing on a notebook  \n",
       "3                                         Showing an image processing  \n",
       "4                                                 Drawing Sailor Moon  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teste4 on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-0000337f1964"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
