{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Generate product attributes and descriptions from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to generate attributes and descriptions of products based on product images in a GCS bucket.  \n",
    "It uses the [Stanford Online Products dataset](https://cvgl.stanford.edu/projects/lifted_struct/) and uses the Vertex AI Imagen for [Captioning](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-captioning) & [VQA](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/visual-question-answering) model to generate product attributes.  \n",
    "It uses the [Gemini](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini) to generate product sales descriptions, using Spark UDFs to parallelize processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### **Steps**\n",
    "Using Spark,\n",
    "1) It reads the table of the [Stanford Online Products dataset](https://cvgl.stanford.edu/projects/lifted_struct/) dataset located in [gs://dataproc-metastore-public-binaries/stanford_online_products](https://console.cloud.google.com/storage/browser/dataproc-metastore-public-binaries/stanford_online_products)    \n",
    "We will create a metadata table poiting to the paths of the image files in the bucket.  \n",
    "2) It calls Vertex AI Imagen for Captioning and VQA to get product attributes for each image.\n",
    "3) It calls Vertex AI Gemini API to get product sales descriptions based on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Make sure the service account running this notebook has the required permissions:\n",
    "\n",
    "- **Run the notebook**\n",
    "  - AI Platform Notebooks Service Agent\n",
    "  - Notebooks Admin\n",
    "  - Vertex AI Administrator\n",
    "- **Read files from bucket**\n",
    "  - Storage Object Viewer\n",
    "- **Run Dataproc jobs**\n",
    "  - Dataproc Service Agent\n",
    "  - Dataproc Worker\n",
    "- **Call Google APIs**\n",
    "  - Service Usage Consumer\n",
    "- **BigQuery**\n",
    "  - BigQuery Data Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, concat\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.min_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using Dataproc Serverless, installed packages are automatically available on all nodes\n",
    "!pip install --upgrade google-cloud-aiplatform\n",
    "# When using a Dataproc cluster, you will need to install these packages during cluster creation: https://cloud.google.com/dataproc/docs/tutorials/python-configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"Image attributes and descriptions generation\") \\\n",
    "  .enableHiveSupport() \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "BINARIES_BUCKET_PATH = \"gs://dataproc-metastore-public-binaries/stanford_online_products/\"\n",
    "binaries_df = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").load(BINARIES_BUCKET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's select the paths of the first 10 product images\n",
    "paths_df = binaries_df.select(\"path\").limit(10)\n",
    "paths_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                                                                          path|\n",
    "|----------------------------------------------------------------------------------------------|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/181714736872_0.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/181661485577_1.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/171860974117_1.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/171860974117_2.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/181661485577_0.JPG|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define prompts to get image attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prompt_color = \"What is the product colors?\"\n",
    "prompt_gender = \"The product shown in the image is most appropriate to be used by men, woman or both?\"\n",
    "prompt_brand = \"What is the brand of the product shown in the image? reply unanswerable if you do not know for sure\"\n",
    "prompt_style = \"What is the style of the product shown in the image? ex: modern, casual, tech\"\n",
    "prompt_material = \"What is the material of the product shown in the image? ex: steel, wood, rubber\"\n",
    "prompt_purpose = \"What is the purpose or usage of this product?\"\n",
    "prompt_year = \"What is the year of the product? reply unanswerable if you do not know for sure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define UDF and call Image Captioning and VQA APIs to generate product attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.vision_models import Image, ImageTextModel\n",
    "\n",
    "vertexai.init(project=project_id, location=\"us-central1\")\n",
    "\n",
    "def visual_qa(prompt, gcs_uri):\n",
    "    \n",
    "    model = ImageTextModel.from_pretrained(\"imagetext@001\")\n",
    "    source_img = Image(gcs_uri=gcs_uri)\n",
    "\n",
    "    if prompt == \"\":\n",
    "        captions = model.get_captions(\n",
    "            image=source_img,\n",
    "            language=\"en\",\n",
    "            number_of_results=1,\n",
    "        )\n",
    "    else:\n",
    "        captions = model.ask_question(\n",
    "            image=source_img,\n",
    "            question=prompt,\n",
    "            number_of_results=1,\n",
    "        )\n",
    "    \n",
    "    return captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "visual_qa_udf = udf(visual_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image_metadata_df = paths_df.withColumn(\"description\", visual_qa_udf(lit(\"\"), col(\"path\"))) \\\n",
    "  .withColumn(\"color\", visual_qa_udf(lit(prompt_color), col(\"path\"))) \\\n",
    "  .withColumn(\"gender\", visual_qa_udf(lit(prompt_gender), col(\"path\"))) \\\n",
    "  .withColumn(\"brand\", visual_qa_udf(lit(prompt_brand), col(\"path\"))) \\\n",
    "  .withColumn(\"style\", visual_qa_udf(lit(prompt_style), col(\"path\"))) \\\n",
    "  .withColumn(\"material\", visual_qa_udf(lit(prompt_material), col(\"path\"))) \\\n",
    "  .withColumn(\"purpose\", visual_qa_udf(lit(prompt_purpose), col(\"path\"))) \\\n",
    "  .withColumn(\"year\", visual_qa_udf(lit(prompt_year), col(\"path\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata_df.show(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image_metadata_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define UDF and call Gemini API to generate product sales descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part , HarmCategory, HarmBlockThreshold\n",
    "\n",
    "vertexai.init(project=project_id, location=\"us-central1\")\n",
    "\n",
    "def gemini_predict(gcs_uri, prompt):\n",
    "      \n",
    "    gemini_pro_vision_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "    config = {\"max_output_tokens\": 2048, \"temperature\": 0.4, \"top_p\": 1, \"top_k\": 32}\n",
    "    safety_config = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    }\n",
    "    \n",
    "    prediction = gemini_pro_vision_model.generate_content([\n",
    "          prompt,\n",
    "          Part.from_uri(gcs_uri, mime_type=\"image/jpeg\")\n",
    "        ],\n",
    "        generation_config=config,\n",
    "        safety_settings=safety_config,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    text_responses = []\n",
    "    for response in prediction:\n",
    "        text_responses.append(response.text)\n",
    "    return \"\".join(text_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_descriptions(gcs_uri, description, color, gender, brand, style, material, purpose, year):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        You are a retail expert and knows how to write beatiful, elegant and concise product descriptions, based on data about the product.\n",
    "        Based on the PRODUCT DATA, and the image of the product, you are able to provide the PRODUCT SALES DESCRIPTION.\n",
    "\n",
    "        Here is one EXAMPLE:\n",
    "\n",
    "        START____________________________________\n",
    "        PRODUCT DATA:\n",
    "        Product description: Brown Fashion Sneakers\n",
    "        Color: brown\n",
    "        Gender: Women\n",
    "        Brand: NONE\n",
    "        Style: Fashion Flat heel\n",
    "        Material: Polyurethane\n",
    "\n",
    "        PRODUCT SALES DESCRIPTION:\n",
    "        A pair of pink sneakers with white soles on a white background is a stylish and comfortable choice for women who want to add a touch of color to their wardrobe. These sneakers are made of polyurethane, which is a durable and lightweight material that will keep your feet comfortable all day long. The flat heel makes them easy to wear for all-day activities, and the lace-up closure ensures a secure fit.\n",
    "        These sneakers are perfect for a variety of occasions, from running errands to running errands. They can be dressed up or down, depending on your personal style. Pair them with a casual dress or jeans for a relaxed look, or dress them up with a skirt or pants for a more formal look.\n",
    "        If you are looking for a stylish and comfortable pair of sneakers, these pink sneakers with white soles are a great option. They are made of durable materials, are easy to wear, and can be dressed up or down.\n",
    "\n",
    "        You are a retail expert and knows how to write beatiful, elegant and concise product descriptions, based on data about the product.\n",
    "        Based on the PRODUCT DATA, and the image of the product, you are able to provide the PRODUCT SALES DESCRIPTION.\n",
    "        \n",
    "        Generate a PRODUCT SALES DESCRIPTION for this product:\n",
    "\n",
    "        START____________________________________\n",
    "        PRODUCT DATA:\n",
    "        Product description: {description}\n",
    "        Color: {color}\n",
    "        Gender: {gender}\n",
    "        Brand: {brand}\n",
    "        Style: {style}\n",
    "        Material: {material}\n",
    "        Purpose: {purpose}\n",
    "        Year: {year}\n",
    "\n",
    "        PRODUCT SALES DESCRIPTION:\n",
    "    \"\"\"\n",
    "\n",
    "    descriptions = gemini_predict(gcs_uri, prompt)\n",
    "    return descriptions\n",
    "    \n",
    "generate_descriptions_udf = udf(generate_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image_descriptions_df = image_metadata_df.withColumn(\"sales_description\", generate_descriptions_udf(\"path\", \"description\", \"color\", \"gender\", \"brand\", \"style\", \"material\", \"purpose\", \"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image_descriptions_df.sort(image_descriptions_df.path.asc()).withColumn(\"url\", regexp_replace(concat(lit(\"https://storage.mtls.cloud.google.com/\"),col(\"path\")), \"gs://\", \"\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                          path|                   description|color|gender|       brand| style|material|     purpose|        year|             sales_description|                           url|\n",
    "|------------------------------|------------------------------|-----|------|------------|------|--------|------------|------------|------------------------------|------------------------------|\n",
    "|gs://dataproc-metastore-pub...|a kitchen with wooden cabin...|brown| women|unanswerable|modern|    wood|     kitchen|unanswerable| This beautiful kitchen is ...|https://storage.mtls.cloud....|\n",
    "|gs://dataproc-metastore-pub...|a close up of a wooden pill...|brown| women|unanswerable|modern|    wood|     cabinet|unanswerable| This beautiful wooden cabi...|https://storage.mtls.cloud....|\n",
    "|gs://dataproc-metastore-pub...|a crystal chandelier is han...|clear| women|unanswerable|modern|   metal|  decoration|unanswerable| This stunning crystal chan...|https://storage.mtls.cloud....|\n",
    "|gs://dataproc-metastore-pub...|a lamp with a giraffe shape...|white| women|unanswerable|modern|    wood|        lamp|unanswerable| This elegant lamp is sure ...|https://storage.mtls.cloud....|\n",
    "|gs://dataproc-metastore-pub...|a brown and white crocheted...|white| women|unanswerable|modern|  rubber|unanswerable|unanswerable| This crocheted brown and w...|https://storage.mtls.cloud....|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runtime-galileo on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-galileo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
