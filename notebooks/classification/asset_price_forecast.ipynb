{
  "cells": [
    {
      "cell_type": "code",
      "id": "generated_license",
      "metadata": {},
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_links",
      "metadata": {},
      "source": [
        "<table align=\"left\">\n",
        "  <td><a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/ai-ml-recipes/blob/main/notebooks/classification/asset_price_forecast.ipynb\"><img src=\"https://avatars.githubusercontent.com/u/33467679?s=200&v=4\" width=\"32px\" alt=\"Colab logo\"> Run in Colab</a></td>\n",
        "  <td><a href=\"https://github.com/GoogleCloudPlatform/ai-ml-recipes/blob/main/notebooks/classification/asset_price_forecast.ipynb\"><img src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" width=\"32px\" alt=\"GitHub logo\"> View on GitHub</a></td>\n",
        "  <td><a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/ai-ml-recipes/main/notebooks/classification/asset_price_forecast.ipynb\"><img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> Open in Vertex AI Workbench</a></td>\n",
        "  <td><a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/GoogleCloudPlatform/ai-ml-recipes/blob/main/notebooks/classification/asset_price_forecast.ipynb\"><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTW1gvOovVlbZAIZylUtf5Iu8-693qS1w5NJw&s\" alt=\"BQ logo\" width=\"35\"> Open in BQ Studio</a></td>\n",
        "  <td><a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fai-ml-recipes%2Fmain%2Fnotebooks/classification/asset_price_forecast.ipynb\"><img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"> Open in Colab Enterprise</a></td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2300e6",
      "metadata": {},
      "source": [
        "# Asset Price Forecast using Iceberg and Prophet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9440e57a",
      "metadata": {},
      "source": [
        "<img src=\"../../docs/images/forecast/gold-forecast.png\" alt=\"drawing\" width=\"800\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_overview",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to forecast asset prices using PySpark, Iceberg, and Prophet. It covers loading data, performing transformations, storing data in an Iceberg table, training a time-series forecasting model with Prophet, and then integrating the predictions back into the Iceberg table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_setup",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "This section sets up the environment by installing necessary libraries, importing modules, defining global variables, and initializing the SparkSession.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_6892eb2c",
      "metadata": {},
      "source": [
        "### Install dependencies\n",
        "\n",
        "Install the required Python packages for PySpark, Google Spark Connect, Dataproc, Pandas, Prophet, and Matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6892eb2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q pyspark==3.5.0 google-spark-connect google-cloud-dataproc pandas prophet matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_d06431b9",
      "metadata": {},
      "source": [
        "### Import libraries\n",
        "\n",
        "Import necessary libraries for Prophet, PySpark, and Google Cloud Dataproc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06431b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from prophet import Prophet\n",
        "\n",
        "from pyspark.sql.functions import col, year\n",
        "\n",
        "from google.cloud import dataproc_v1\n",
        "from google.cloud.dataproc_v1 import Session, SparkConnectConfig\n",
        "from google.cloud.spark_connect import GoogleSparkSession\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_c8860965",
      "metadata": {},
      "source": [
        "### Set global variables\n",
        "\n",
        "Define project-specific variables, including your GCP project ID, desired location, Spark template ID, and GCS paths for input data and Iceberg warehouse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8860965",
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = \"<YOUR_GCP_PROJECT>\"\n",
        "location = \"<YOUR_LOCATION>\"  \n",
        "\n",
        "serverless_spark_template_id = \"spark-serverless-runtime\"\n",
        "\n",
        "csv_path = 'gs://dataproc-metastore-public-binaries/asset_price_forecast/asset_price_forecast.csv'\n",
        "\n",
        "iceberg_warehouse_gcs_path = \"gs://<YOUR_ICEBERG_GCS_BUCKET>/iceberg/data\"\n",
        "iceberg_catalog_name = \"spark_catalog_demo\"\n",
        "iceberg_dataset = \"finance\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_9f4a9cb5",
      "metadata": {},
      "source": [
        "### Create a Spark session template\n",
        "\n",
        "This function creates a Dataproc Spark session template if it doesn't already exist. The template configures Spark with Iceberg extensions and BigQuery Metastore for catalog management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4a9cb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import google.api_core.exceptions\n",
        "\n",
        "def create_session_template():\n",
        "    \"\"\"Creates a session template and handles the case where it already exists.\"\"\"\n",
        "    full_template_name = f\"projects/{project_id}/locations/{location}/sessionTemplates/{serverless_spark_template_id}\"\n",
        "\n",
        "    template = dataproc_v1.SessionTemplate()\n",
        "    template.description = \"A standard template for interactive PySpark sessions.\"\n",
        "    template.runtime_config = {\n",
        "        \"version\": \"2.2\",\n",
        "        \"properties\": {\n",
        "            \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
        "            f\"spark.sql.catalog.{iceberg_catalog_name}\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
        "            f\"spark.sql.catalog.{iceberg_catalog_name}.catalog-impl\": \"org.apache.iceberg.gcp.bigquery.BigQueryMetastoreCatalog\",\n",
        "            f\"spark.sql.catalog.{iceberg_catalog_name}.gcp_project\": project_id,\n",
        "            f\"spark.sql.catalog.{iceberg_catalog_name}.gcp_location\": location,\n",
        "            f\"spark.sql.catalog.{iceberg_catalog_name}.warehouse\": iceberg_warehouse_gcs_path,\n",
        "            \"spark.sql.warehouse.dir\": \"/tmp/hive/data/warehouse\"\n",
        "        }\n",
        "    }\n",
        "    template.spark_connect_session = {}\n",
        "    template.name = full_template_name\n",
        "\n",
        "    client_options = {\"api_endpoint\": f\"{location}-dataproc.googleapis.com:443\"}\n",
        "    client = dataproc_v1.SessionTemplateControllerClient(client_options=client_options)\n",
        "    parent = client.common_location_path(project_id, location)\n",
        "\n",
        "    try:\n",
        "        request = dataproc_v1.CreateSessionTemplateRequest(\n",
        "            parent=parent,\n",
        "            session_template=template\n",
        "        )\n",
        "        result = client.create_session_template(request=request)\n",
        "        print(f\"Session template created: {result.name}\")\n",
        "    except google.api_core.exceptions.AlreadyExists:\n",
        "        print(f\"Session template '{serverless_spark_template_id}' already exists.\")\n",
        "        request = dataproc_v1.GetSessionTemplateRequest(name=full_template_name)\n",
        "        result = client.get_session_template(request=request)\n",
        "        print(f\"Using existing session template: {result.name}\")\n",
        "\n",
        "create_session_template()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_de001e63",
      "metadata": {},
      "source": [
        "### Initialize the SparkSession\n",
        "\n",
        "Create a `GoogleSparkSession` connected to the specified Dataproc session template. This sets up the distributed Spark environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de001e63",
      "metadata": {},
      "outputs": [],
      "source": [
        "session_config = Session()\n",
        "session_config.spark_connect_session = SparkConnectConfig()\n",
        "session_config.session_template = f\"projects/{project_id}/locations/{location}/sessionTemplates/{serverless_spark_template_id}\"\n",
        "spark = GoogleSparkSession.builder.projectId(project_id).location(location).googleSessionConfig(session_config).getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_3c6797c4-e1be-4eca-9775-12e86128b81c",
      "metadata": {},
      "source": [
        "## Data Loading and Preparation\n",
        "\n",
        "### Load the dataset\n",
        "\n",
        "Load the asset price data from the specified CSV path into a Spark DataFrame. The `header` and `inferSchema` options are used to correctly parse the CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6797c4-e1be-4eca-9775-12e86128b81c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_path)\n",
        "df.count()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_b25618aa-f819-424b-a34b-695aa848f4a0",
      "metadata": {},
      "source": [
        "### Optimize and transform the DataFrame\n",
        "\n",
        "Drop unneeded columns ('High', 'Low', 'Open', 'Volume') and extract the year from the 'date' column, which will be used for partitioning the Iceberg table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25618aa-f819-424b-a34b-695aa848f4a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_optimized = df.drop('High', 'Low', 'Open', 'Volume')\n",
        "df_optimized = df_optimized.withColumn('year', year(col('date')))\n",
        "df_optimized.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_bba976f3",
      "metadata": {},
      "source": [
        "### Create Iceberg database\n",
        "\n",
        "Create a new database within the Iceberg catalog if it doesn't already exist. This database will house our asset price table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba976f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {iceberg_catalog_name}.{iceberg_dataset}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_88a78a2c-3209-4356-92c9-a548d8f6c92b",
      "metadata": {},
      "source": [
        "### Write data to Iceberg table\n",
        "\n",
        "Write the optimized historical data to an Iceberg table named `gold_price`. The table is partitioned by 'year' for optimized querying, and existing data is overwritten.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a78a2c-3209-4356-92c9-a548d8f6c92b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_optimized.write.format('iceberg').mode('overwrite').partitionBy('year').saveAsTable(f'{iceberg_catalog_name}.{iceberg_dataset}.gold_price')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_92137c35-0e0c-49bb-874a-b1bf5ab95e2d",
      "metadata": {},
      "source": [
        "## Model Training\n",
        "\n",
        "### Convert Spark DataFrame to Pandas DataFrame\n",
        "\n",
        "Convert the Spark DataFrame containing historical asset prices into a Pandas DataFrame, which is required as input for the Prophet library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92137c35-0e0c-49bb-874a-b1bf5ab95e2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pandas = df_optimized.toPandas()\n",
        "df_pandas.count()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_6daf8726-c67c-4c50-98a5-64cff93a2a14",
      "metadata": {},
      "source": [
        "### Initialize and train the Prophet model\n",
        "\n",
        "Instantiate the Prophet model with a specified confidence interval and train it using the prepared historical data. Prophet automatically handles trend, seasonality, and holidays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6daf8726-c67c-4c50-98a5-64cff93a2a14",
      "metadata": {},
      "outputs": [],
      "source": [
        "series = df_pandas.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
        "confidence_interval = 0.9\n",
        "model = Prophet(interval_width=confidence_interval)\n",
        "model.fit(series)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_294ee85a-ee13-4700-a00e-986087f8926b",
      "metadata": {},
      "source": [
        "## Prediction and Visualization\n",
        "\n",
        "### Generate future predictions\n",
        "\n",
        "Create a DataFrame of future dates for forecasting and then use the trained Prophet model to predict asset prices for these future dates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294ee85a-ee13-4700-a00e-986087f8926b",
      "metadata": {},
      "outputs": [],
      "source": [
        "forecast_period = 365\n",
        "future = model.make_future_dataframe(periods=forecast_period)\n",
        "forecast = model.predict(future)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_9b3f253f-40c7-4208-9c7a-f4987b60e85c",
      "metadata": {},
      "source": [
        "### Plot the forecast\n",
        "\n",
        "Visualize the historical data and the forecasted asset prices, including the uncertainty intervals. The plot provides a clear overview of the predicted trend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3f253f-40c7-4208-9c7a-f4987b60e85c",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig1 = model.plot(forecast)\n",
        "fig1.gca().set_title(\"Gold Spot Price Forecast\", size=16)\n",
        "fig1.gca().set_xlabel(\"Date\")\n",
        "fig1.gca().set_ylabel(\"Price USD/Ounce\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_eea8fe86-0554-495c-9da2-df82a8dc1e55",
      "metadata": {},
      "source": [
        "## Integrate Forecasted Data\n",
        "\n",
        "### Prepare forecast data for storage\n",
        "\n",
        "Filter the forecast to show only future predictions, rename columns to match the original schema, convert date formats, and convert the Pandas DataFrame back into a Spark DataFrame for integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea8fe86-0554-495c-9da2-df82a8dc1e55",
      "metadata": {},
      "outputs": [],
      "source": [
        "forecast1 = forecast[['ds', 'yhat']][forecast['ds']> '2025-07-17']\n",
        "forecast1.columns = ['Date', 'Close']\n",
        "forecast1['Date'] = forecast1['Date'].dt.date\n",
        "df_forecast = spark.createDataFrame(forecast1)\n",
        "df_forecast = df_forecast.withColumn('year', year(col('date')))\n",
        "df_forecast.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_09c226ca-53a2-48c5-885c-83adba602be9",
      "metadata": {},
      "source": [
        "### Combine historical and forecasted data\n",
        "\n",
        "Merge the original historical data with the newly generated future forecast data into a single Spark DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c226ca-53a2-48c5-885c-83adba602be9",
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_df = df_optimized.unionByName(df_forecast)\n",
        "combined_df.tail(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generated_explanation_b6626681-753a-4162-83cb-61a0c5099108",
      "metadata": {},
      "source": [
        "### Append combined data to Iceberg table\n",
        "\n",
        "Append the combined historical and forecasted data to the `gold_price` Iceberg table. This updates the table with the latest predictions without overwriting historical data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6626681-753a-4162-83cb-61a0c5099108",
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_df.write.format('iceberg').mode('append').partitionBy('year').saveAsTable(f'{iceberg_catalog_name}.{iceberg_dataset}.gold_price')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}