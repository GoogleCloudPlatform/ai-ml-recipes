{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Generate product attributes and descriptions from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to generate attributes and descriptions of products based on product images in a GCS bucket.  \n",
    "It uses the [Stanford Online Products dataset](https://cvgl.stanford.edu/projects/lifted_struct/).\n",
    "It uses the [Gemini](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini) to generate product attributes and sales descriptions, using Spark UDFs to parallelize processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### **Steps**\n",
    "Using Spark,\n",
    "1) It reads the table of the [Stanford Online Products dataset](https://cvgl.stanford.edu/projects/lifted_struct/) dataset located in [gs://dataproc-metastore-public-binaries/stanford_online_products](https://console.cloud.google.com/storage/browser/dataproc-metastore-public-binaries/stanford_online_products)    \n",
    "We will create a metadata table poiting to the paths of the image files in the bucket.   \n",
    "2) It calls Vertex AI Gemini API to get product attributes and product sales descriptions based on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Make sure the service account running this notebook has the required permissions:\n",
    "\n",
    "- **Run the notebook**\n",
    "  - AI Platform Notebooks Service Agent\n",
    "  - Notebooks Admin\n",
    "  - Vertex AI Administrator\n",
    "- **Read files from bucket**\n",
    "  - Storage Object Viewer\n",
    "- **Run Dataproc jobs**\n",
    "  - Dataproc Service Agent\n",
    "  - Dataproc Worker\n",
    "- **Call Google APIs**\n",
    "  - Service Usage Consumer\n",
    "- **BigQuery**\n",
    "  - BigQuery Data Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using Dataproc Serverless, installed packages are automatically available on all nodes\n",
    "!pip3 install --upgrade google-cloud-aiplatform -q\n",
    "# When using a Dataproc cluster, you will need to install these packages during cluster creation: https://cloud.google.com/dataproc/docs/tutorials/python-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from pyspark.sql.functions import regexp_replace, concat\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import requests\n",
    "\n",
    "import vertexai\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.min_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"Image attributes and descriptions generation\") \\\n",
    "  .enableHiveSupport() \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "BINARIES_BUCKET_PATH = \"gs://dataproc-metastore-public-binaries/stanford_online_products/\"\n",
    "binaries_df = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").load(BINARIES_BUCKET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's select the paths of the first 10 product images\n",
    "paths_df = binaries_df.select(\"path\").limit(10)\n",
    "paths_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                                                                          path|\n",
    "|----------------------------------------------------------------------------------------------|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/181714736872_0.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/181661485577_1.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/171860974117_1.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/171860974117_2.JPG|\n",
    "|gs://dataproc-metastore-public-binaries/stanford_online_products/sofa_final/181661485577_0.JPG|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define prompt to get image attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = [\n",
    "        \"\"\"You are a retail expert and your job is to generate structured information about products based on the images of these products.\"\"\",  \n",
    "        \"\"\"You also know how to write beatiful, elegant and concise product descriptions, based on data about a product.\"\"\",\n",
    "        \"\"\"Respond in the JSON format.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_prompt():\n",
    "  return f\"\"\"\n",
    "<h5>Instructions</h5>\n",
    "Analyze the content and generate the following attributes of these products based on the following questions:\n",
    "\n",
    "product: \"What product is this?\"\n",
    "color: \"What is the product colors?\"\n",
    "gender: \"The product shown in the image is most appropriate to be used by men, woman, all or other?\"\n",
    "brand: \"What is the brand of the product shown in the image? reply unanswerable if you do not know for sure\"\n",
    "style: \"What is the style of the product shown in the image? ex: modern, casual, tech\"\n",
    "material: \"What is the material of the product shown in the image? ex: steel, wood, rubber\"\n",
    "purpose: \"What is the purpose or usage of this product?\"\n",
    "year: \"What is the year of the product? reply unanswerable if you do not know for sure\"\n",
    "sales_description: \"Beatiful, elegant and concise product description\"\n",
    "\n",
    "<h4>Example</h4>\n",
    "{{\n",
    "product: \"Brown Fashion Sneakers\"\n",
    "color: \"Brown\"\n",
    "gender: \"Woman\"\n",
    "brand: \"unanswerable\"\n",
    "style: \"Fashion Flat heel\"\n",
    "material: \"Polyurethane\"\n",
    "purpose: \"unanswerable\"\n",
    "year: \"unanswerable\"\n",
    "sales_description: \"A pair of brown sneakers with white soles on a white background is a stylish and comfortable choice for women who want to add a touch of color to their wardrobe. These sneakers are made of polyurethane, which is a durable and lightweight material that will keep your feet comfortable all day long. The flat heel makes them easy to wear for all-day activities, and the lace-up closure ensures a secure fit. These sneakers are perfect for a variety of occasions, from running errands to running errands. They can be dressed up or down, depending on your personal style. Pair them with a casual dress or jeans for a relaxed look, or dress them up with a skirt or pants for a more formal look.\"\n",
    "}}\n",
    "        \n",
    "<h4>Response</h4>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"product\": {\"type\": \"string\"},\n",
    "        \"color\": {\"type\": \"string\"},\n",
    "        \"gender\": {\"type\": \"string\"},\n",
    "        \"brand\": {\"type\": \"string\"},\n",
    "        \"style\": {\"type\": \"string\"},\n",
    "        \"material\": {\"type\": \"string\"},\n",
    "        \"purpose\": {\"type\": \"string\"},\n",
    "        \"year\": {\"type\": \"string\"},\n",
    "        \"sales_description\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"product\",\"color\",\"gender\",\"brand\",\"style\",\"material\",\"purpose\",\"year\",\"sales_description\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Define UDF and call Gemini API to generate product attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part, Image, Content, HarmCategory, HarmBlockThreshold\n",
    "\n",
    "def predict(uri, prompt, system_instructions=system_instructions, response_schema=response_schema, content_type=\"image/jpg\", temperature=1, model_name=\"gemini-2.5-flash\"):\n",
    "\n",
    "    model = GenerativeModel(model_name=model_name, system_instruction=system_instructions)\n",
    "    \n",
    "    prompt_content = Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            Part.from_uri(uri, content_type),\n",
    "            Part.from_text(prompt)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(\n",
    "        prompt_content,\n",
    "        generation_config = GenerationConfig(\n",
    "            temperature=temperature, response_mime_type=\"application/json\", response_schema=response_schema\n",
    "        ),\n",
    "        safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_udf = udf(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image_metadata_df = paths_df.withColumn(\"gemini_analysis\", predict_udf(col(\"path\"), lit(attributes_prompt())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata_df.show(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "image_metadata_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('product', StringType(), True),\n",
    "        StructField('color', StringType(), True),\n",
    "        StructField('gender', StringType(), True),\n",
    "        StructField('brand', StringType(), True),\n",
    "        StructField('style', StringType(), True),\n",
    "        StructField('material', StringType(), True),\n",
    "        StructField('purpose', StringType(), True),\n",
    "        StructField('year', StringType(), True),\n",
    "        StructField('sales_description', StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = image_metadata_df.withColumn(\"exploded_data\", from_json(regexp_replace(regexp_replace(col(\"gemini_analysis\"),\"json\", \"\"),\"```\",\"\"), schema))\\\n",
    "    .select(col('path'),col('exploded_data.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.withColumn(\"url\", regexp_replace(concat(lit(\"https://storage.mtls.cloud.google.com/\"),col(\"path\")), \"gs://\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_final.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta-runtime on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-delta-runtime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
