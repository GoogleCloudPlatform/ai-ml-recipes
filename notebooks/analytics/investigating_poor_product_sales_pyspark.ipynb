{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apache_license",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7665b2ac",
      "metadata": {},
      "source": [
        "# Customer Insights: Investigating Declining Sales with PySpark and Gemini\n",
        "\n",
        "This notebook demonstrates a comprehensive data science approach to investigating declining product sales using **Apache Spark (PySpark)** and **Vertex AI Gemini**. We will combine distributed data processing with AI-powered sentiment analysis and machine learning to uncover actionable business intelligence.\n",
        "\n",
        "## Objectives\n",
        "1. **Validate sales shortfall** using Spark DataFrames and Matplotlib.\n",
        "2. **Analyze customer sentiment** at scale using Generic AI (Gemini) through Spark UDFs.\n",
        "3. **Predict conversion factors** using distributed XGBoost for Spark.\n",
        "4. **Identify root causes** for declining sales of the \"Quantum AI Speaker 2\" product."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup_section",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "This section sets up the environment by installing necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d2b965",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install google-cloud-aiplatform xgboost -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports_init_section",
      "metadata": {},
      "source": [
        "### Imports and Initialization\n",
        "\n",
        "Import the required libraries, initialize a Spark session, define project constants, and initialize the Vertex AI SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215b8508",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import *\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, Content\n",
        "from xgboost.spark import SparkXGBClassifier\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Create Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PoorProductSalesInvestigation\") \\\n",
        "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Constants\n",
        "PROJECT_ID = \"<PROJECT_ID>\"\n",
        "LOCATION = \"us-central1\"\n",
        "BUCKET_PATH = \"gs://data-analytics-golden-demo/demo-data/global-gadgets-fork/\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7821b14",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "Load data from GCS into Spark DataFrames. These datasets represent user sessions, demographics, and product reviews for Global Gadgets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8acbee3",
      "metadata": {},
      "outputs": [],
      "source": [
        "tables = [\n",
        "    'monthly_product_sales',\n",
        "    'product_reviews',\n",
        "    'session_to_user_map',\n",
        "    'sessions',\n",
        "    'sessions_reviews',\n",
        "    'user_info'\n",
        "]\n",
        "\n",
        "dfs = {}\n",
        "for table in tables:\n",
        "    # Load each parquet folder as a DataFrame\n",
        "    dfs[table] = spark.read.parquet(f\"{BUCKET_PATH}{table}\")\n",
        "    print(f\"Loaded {table}: {dfs[table].count()} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ecba9d",
      "metadata": {},
      "source": [
        "## Visualizing the Sales Shortfall\n",
        "We compare the sales trajectory of V1 vs V2 based on 'Months Since Launch'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4430086c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales = dfs['monthly_product_sales']\n",
        "\n",
        "# Prepare data for V1 and V2 comparison\n",
        "df_v1 = df_sales.select(F.col(\"V1_months_since_launch\").alias(\"months_since_launch\"), F.col(\"V1_Sales\").alias(\"sales\")).withColumn(\"product\", F.lit(\"V1\"))\n",
        "df_v2 = df_sales.select(F.col(\"V2_months_since_launch\").alias(\"months_since_launch\"), F.col(\"V2_Sales\").alias(\"sales\")).withColumn(\"product\", F.lit(\"V2\"))\n",
        "\n",
        "df_combined = df_v1.union(df_v2).filter(\"sales > 0\").toPandas()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "for label, group_df in df_combined.groupby('product'):\n",
        "    plt.plot(group_df['months_since_launch'], group_df['sales'], label=f\"{label} Sales\", marker='o')\n",
        "\n",
        "plt.xlabel('Months Since Launch')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Sales Comparison of V1 and V2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec40818",
      "metadata": {},
      "source": [
        "## Distributed Sentiment Scoring with Gemini\n",
        "We use a Spark UDF to leverage Gemini for scoring product reviews in parallel across the cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30532e67",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sentiment_score(review_text):\n",
        "    model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "    # Note: System instructions and response schemas are best practice for structured output\n",
        "    prompt = f\"\"\"\n",
        "    Score the following product review for its sentiment towards specific features. \n",
        "    Features: \"AI Assistant Pro\", \"Audio Quality\", \"Seamless Connectivity\", \"Smart Home Integration\".\n",
        "    Scale: -2 (Very Negative) to +2 (Very Positive). Use 0 if the feature is not mentioned.\n",
        "    Review: {review_text}\n",
        "    Respond in valid JSON format with keys: ai_assistant_pro_score, audio_quality_score, seamless_connectivity_score, smart_home_integration_score.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"{{'error': '{str(e)}'}}\"\n",
        "\n",
        "sentiment_udf = F.udf(get_sentiment_score, StringType())\n",
        "\n",
        "df_reviews = dfs['product_reviews']\n",
        "# Apply UDF to score reviews\n",
        "# Note: In a production environment with many reviews, consider batching or rate limiting.\n",
        "df_scored = df_reviews.withColumn(\"gemini_output\", sentiment_udf(F.col(\"review_body\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "parsing_gemini_output",
      "metadata": {},
      "source": [
        "### Parsing Gemini Output\n",
        "\n",
        "Parse the JSON output from the Gemini model, extracting the sentiment scores for each feature into structured columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e673f36d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse JSON output from Gemini into structured columns\n",
        "schema = StructType([\n",
        "    StructField(\"ai_assistant_pro_score\", IntegerType()),\n",
        "    StructField(\"audio_quality_score\", IntegerType()),\n",
        "    StructField(\"seamless_connectivity_score\", IntegerType()),\n",
        "    StructField(\"smart_home_integration_score\", IntegerType())\n",
        "])\n",
        "\n",
        "# Clean the Gemini output if it contains markdown formatting\n",
        "df_review_scores = df_scored.withColumn(\"cleaned_output\", F.regexp_replace(F.col(\"gemini_output\"), \"|\", \"\")) \\\n",
        "    .withColumn(\"scores\", F.from_json(F.col(\"cleaned_output\"), schema))\n",
        "\n",
        "df_review_scores_final = df_review_scores.select(\"review_id\", \"scores.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "review_scores_overview",
      "metadata": {},
      "source": [
        "### Review Scores Overview\n",
        "\n",
        "Display the first few rows of the final DataFrame containing the parsed sentiment scores to verify the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff47e62b-49db-4e83-86f4-117712e09d59",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_review_scores_final.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cache_scored_reviews",
      "metadata": {},
      "source": [
        "### Cache Scored Reviews\n",
        "\n",
        "Cache the `df_review_scores_final` DataFrame in memory for faster access in subsequent operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52a8e90-7da7-40d7-89c4-1209a98c91b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_review_scores_final.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574ca76c",
      "metadata": {},
      "source": [
        "## Data Consolidation\n",
        "We join session data, user demographics, and sentiment scores into a single wide table for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc24f504",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sessions = dfs['sessions']\n",
        "df_sessions_reviews = dfs['sessions_reviews']\n",
        "df_user_map = dfs['session_to_user_map']\n",
        "df_user_info = dfs['user_info']\n",
        "\n",
        "# Unnest (explode) reviews seen in each session\n",
        "df_sessions_unnested = df_sessions_reviews.withColumn(\"review_id\", F.explode(F.split(F.regexp_replace(F.col(\"reviews_seen\"), \"'\", \"\"), \", \")))\n",
        "\n",
        "# Join tables together\n",
        "df_final = df_sessions.join(df_sessions_unnested, \"session_id\") \\\n",
        "    .join(df_review_scores_final, \"review_id\") \\\n",
        "    .join(df_user_map, \"session_id\") \\\n",
        "    .join(df_user_info, \"user_id\")\n",
        "\n",
        "# Create flags for negative reviews seen (score = -2)\n",
        "df_final = df_final.withColumn(\"AI_Assistant_neg\", F.when(F.col(\"ai_assistant_pro_score\") == -2, 1).otherwise(0)) \\\n",
        "    .withColumn(\"Audio_Quality_neg\", F.when(F.col(\"audio_quality_score\") == -2, 1).otherwise(0)) \\\n",
        "    .withColumn(\"Connectivity_neg\", F.when(F.col(\"seamless_connectivity_score\") == -2, 1).otherwise(0)) \\\n",
        "    .withColumn(\"Smart_Home_neg\", F.when(F.col(\"smart_home_integration_score\") == -2, 1).otherwise(0))\n",
        "\n",
        "# Aggregate to session level and cast 'converted' to integer to support ML evaluators\n",
        "df_session_ml = df_final.groupBy(\"session_id\", \"gender\", \"age_range\", \"urbanicity\", \"device_type\", \"converted\") \\\n",
        "    .agg(F.max(\"AI_Assistant_neg\").alias(\"AI_Assistant_neg\"),\n",
        "         F.max(\"Audio_Quality_neg\").alias(\"Audio_Quality_neg\"),\n",
        "         F.max(\"Connectivity_neg\").alias(\"Connectivity_neg\"),\n",
        "         F.max(\"Smart_Home_neg\").alias(\"Smart_Home_neg\")) \\\n",
        "    .withColumn(\"converted\", F.col(\"converted\").cast(\"integer\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb30ccb1",
      "metadata": {},
      "source": [
        "## Distributed Machine Learning with XGBoost\n",
        "Using the `SparkXGBClassifier` to train a model across the cluster to identify which factors most influence purchase decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d560fbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost.spark import SparkXGBClassifier\n",
        "\n",
        "# Pre-processing categorical features\n",
        "categorical_cols = [\"gender\", \"age_range\", \"urbanicity\", \"device_type\"]\n",
        "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\") for c in categorical_cols]\n",
        "\n",
        "# Feature assembly\n",
        "feature_cols = [f\"{c}_idx\" for c in categorical_cols] + [\"AI_Assistant_neg\", \"Audio_Quality_neg\", \"Connectivity_neg\", \"Smart_Home_neg\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "# Build ML Pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler])\n",
        "pipeline_model = pipeline.fit(df_session_ml)\n",
        "df_ready = pipeline_model.transform(df_session_ml)\n",
        "\n",
        "# Split into Train/Test\n",
        "train_df, test_df = df_ready.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train Distributed XGBoost Classifier\n",
        "xgb_classifier = SparkXGBClassifier(\n",
        "    features_col=\"features\",\n",
        "    label_col=\"converted\",\n",
        "    num_workers=2,\n",
        "    max_depth=5,\n",
        "    n_estimators=50\n",
        ")\n",
        "\n",
        "xgb_model = xgb_classifier.fit(train_df)\n",
        "predictions = xgb_model.transform(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a56f26",
      "metadata": {},
      "source": [
        "## Evaluation and Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f958fec",
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"converted\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Feature Importance Visualization\n",
        "importances_dict = xgb_model.get_feature_importances()\n",
        "# Map 'f0', 'f1' etc. (or numerical indices) to feature names\n",
        "try:\n",
        "    # If keys are strings like 'f0', 'f1'...\n",
        "    importances = {feature_cols[int(k.replace('f', ''))]: v for k, v in importances_dict.items()}\n",
        "except:\n",
        "    # If keys are already integers...\n",
        "    importances = {feature_cols[int(k)]: v for k, v in importances_dict.items()}\n",
        "\n",
        "feat_importances = pd.Series(importances)\n",
        "feat_importances.sort_values().plot(kind='barh', figsize=(10, 6), color='skyblue')\n",
        "plt.title('Feature Importances in Predicting Conversions')\n",
        "plt.xlabel('Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1d8ee1",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "The analysis confirms that negative sentiment towards the **AI Assistant Pro** is the primary driver of declining conversion rates. By transitioning this investigation to **PySpark**, we have enabled this workflow to scale across massive datasets, leveraging the power of **vertex AI Gemini** and **Distributed XGBoost** for faster, more intelligent business decisions."
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "9c39b79e5d2e7072beb4bd59-new-runtime",
      "name": "workbench-notebooks.m129",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
