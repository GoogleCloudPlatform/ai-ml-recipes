{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "Purchase_Predictions_Spark (2)"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "eBQvliwsLiZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario\n",
        "\n",
        "TheLook, a hypothetical eCommerce clothing retailer, stores data on customers, products, orders, logistics, web events, and digital marketing campaigns in BigQuery. The company wants to leverage the team's existing SQL and PySpark expertise to analyze this data using Apache Spark.\n",
        "\n",
        "To avoid manual infrastructure provisioning or tuning for Spark, TheLook seeks an auto-scaling solution that allows them to focus on workloads rather than cluster management. Additionally, they want to minimize the effort required to integrate Spark and BigQuery while staying within the BigQuery Studio environment, possibly using BigQuery notebooks.\n",
        "\n",
        "# Approach\n",
        "\n",
        "In this use case, we will demonstrate how to build a logistic regression classification model using PySpark to predict whether a user will make a purchase. The entire workflow is executed within a Colab Enterprise notebook in BigQuery Studio, taking advantage of the built-in serverless Spark engine. This approach allows our data science team to use familiar PySpark libraries for data exploration and model training directly on data stored in BigQuery, creating a seamless experience from data to model within a single, integrated environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "QCcazsyjJvXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Setup**\n",
        "\n",
        "The following steps create resources that will be used throughout the tutorial."
      ],
      "metadata": {
        "id": "RtgdfcrNWNkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enable the following APIs and then **refresh the page**."
      ],
      "metadata": {
        "id": "pVU8AVZ5p1cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud services enable cloudaicompanion.googleapis.com dataproc.googleapis.com"
      ],
      "metadata": {
        "id": "Uqq6F2IwXEu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries."
      ],
      "metadata": {
        "id": "eO48u79FqCs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ $(pip show numpy 2>/dev/null | grep 'Version:' | sed 's/Version: \\([0-9]\\+\\.[0-9]\\+\\).*/\\1/') != \"1.26\" ]; then pip install -U numpy==1.26; fi"
      ],
      "metadata": {
        "id": "NLAcVWG5rXWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure a project id and location."
      ],
      "metadata": {
        "id": "YHIbYWxZWxk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"\" # @param {type:\"string\"}\n",
        "\n",
        "LOCATION = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "SzD0y_2iBsoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets?utm_campaign=CDR_0x225cfd13_default_b407565440&utm_source=external&utm_medium=web) or set an existing one.\n"
      ],
      "metadata": {
        "id": "cYJ_MOKbW3re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "BUCKET_NAME = f\"{PROJECT_ID}-demo\"\n",
        "\n",
        "# storage_client = storage.Client(project=PROJECT_ID)\n",
        "# bucket_obj = storage_client.create_bucket(BUCKET_NAME, location=LOCATION)"
      ],
      "metadata": {
        "id": "4PCe-xdgBoZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Configure Spark**\n",
        "\n",
        "*   Set up the Spark environment: It imports necessary\n",
        "libraries for connecting to Dataproc and using PySpark.\n",
        "*   Configure the Dataproc session: It creates and configures a Spark Session with the necessary parameters, providing the spark object for subsequent Spark operations.\n",
        "\n",
        "This step can also be accomplished in a single line of code below.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "spark = DataprocSparkSession.builder.getOrCreate()\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RVDKd--rJ-_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
        "from google.cloud.dataproc_v1 import Session\n",
        "\n",
        "session = Session()\n",
        "\n",
        "session.runtime_config.version = \"2.3\"\n",
        "\n",
        "# You can optionally configure Spark properties as well. See https://cloud.google.com/dataproc-serverless/docs/concepts/properties.\n",
        "session.runtime_config.properties = {\n",
        "  'spark.dynamicAllocation.enabled': 'false',\n",
        "}\n",
        "\n",
        "spark = (\n",
        "    DataprocSparkSession.builder\n",
        "      .appName(\"CustomSparkSession\")\n",
        "      .dataprocSessionConfig(session)\n",
        "      .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "h_tqpdNgg-qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Load data**\n"
      ],
      "metadata": {
        "id": "ZJCWG4vrK8dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load each table into Spark and register them as SparkSQL tables."
      ],
      "metadata": {
        "id": "MxS70d6xVAYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read thelook_ecommerce.users from BigQuery and create a temporary view\n",
        "users = spark.read.format(\"bigquery\").option(\"table\", \"bigquery-public-data.thelook_ecommerce.users\").load()\n",
        "users.createOrReplaceTempView(\"users\")\n",
        "\n",
        "# Read thelook_ecommerce.order_items from BigQuery\n",
        "order_items = spark.read.format(\"bigquery\").option(\"table\", \"bigquery-public-data.thelook_ecommerce.order_items\").load()\n",
        "order_items.createOrReplaceTempView(\"order_items\")"
      ],
      "metadata": {
        "id": "ClRTDEzzLB8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Data exploration**\n",
        "\n",
        "Bigquery Studio can leverage Gemini for [advanced code completion capabilities](https://cloud.google.com/bigquery/docs/write-sql-gemini#generate_python_code?utm_campaign=CDR_0x225cfd13_default_b407565440&utm_source=external&utm_medium=web) which can use Natual Language to perform exploratory analysis using SQL and even generate PySpark Code for Feature Engineering.\n",
        "\n",
        "Try the following examples.\n",
        "\n",
        "**Prompt 1**: Use Spark to explore the users table and show the first 10 rows.\n",
        "\n",
        "**Prompt 2**: Use Spark to explore the order_items table and show the first 10 rows.\n",
        "\n",
        "**Prompt 3**: Generate PySpark code to show the top 5 most frequent countries in the users table. Display the country and the number of users from each country.\n",
        "\n",
        "**Prompt 4**: Generate PySpark code to find the average sale price of items in the order_items table.\n",
        "\n",
        "**Prompt 5**: Using the table \"my_dataset.users\", generate code to plot country vs traffic source using a suitable plotting library.\n",
        "\n",
        "**Prompt 6:** Create a histogram showing the distribution of \"age\", \"country_hash\", \"gender_hash\", \"traffic_source_hash\""
      ],
      "metadata": {
        "id": "3orI5dVOMNdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use Spark to explore the users table and show the first 10 rows.\n",
        "\n",
        "users.show(10)"
      ],
      "metadata": {
        "id": "U_B1PuIuW4J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use Spark to explore the order_items table and show the first 10 rows.\n",
        "\n",
        "order_items.show(10)"
      ],
      "metadata": {
        "id": "ekdFabYZXbnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate PySpark code to show the top 5 most frequent countries in the users table. Display the country and the number of users from each country. All imports should use the Spark connect API, not the regular API.\n",
        "\n",
        "from pyspark.sql.functions import col, count, desc\n",
        "\n",
        "users.groupBy(\"country\").agg(count(\"*\").alias(\"count\")).orderBy(desc(\"count\")).limit(5).show()"
      ],
      "metadata": {
        "id": "7VONSq-SXe1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to find the average sale price of items in the order_items table. All imports should use the Spark connect API, not the regular API.\n",
        "\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "order_items.agg(avg(\"sale_price\")).show()"
      ],
      "metadata": {
        "id": "m1u21g3oX6Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create a histogram showing the distribution of \"age\", \"country_hash\", \"gender_hash\", \"traffic_source_hash\"\n",
        "\n",
        "import hashlib\n",
        "\n",
        "def hash_col(df, col):\n",
        "    df[f'{col}_hash'] = df[col].apply(lambda x: int(hashlib.sha256(x.encode('utf-8')).hexdigest(), 16) % 10**8)\n",
        "    return df\n",
        "\n",
        "users_df = users.toPandas()\n",
        "users_df = hash_col(users_df, 'country')\n",
        "users_df = hash_col(users_df, 'gender')\n",
        "users_df = hash_col(users_df, 'traffic_source')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.hist(users_df['age'], bins=20)\n",
        "plt.title('Age Distribution')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.hist(users_df['country_hash'], bins=20)\n",
        "plt.title('Country Hash Distribution')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.hist(users_df['gender_hash'], bins=20)\n",
        "plt.title('Gender Hash Distribution')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.hist(users_df['traffic_source_hash'], bins=20)\n",
        "plt.title('Traffic Source Hash Distribution')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CmuWyKOTrM-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 4: Feature Engineering**\n",
        "\n",
        "In this step, we derive two key columns from the input data:\n",
        "\n",
        "**Creation of features column**:\n",
        "It combines user attributes (age, hashed categorical features) into a numerical array, preparing them for a machine learning model.\n",
        "\n",
        "**Generation of label column:**\n",
        "It creates a binary target variable indicating whether a user has made a purchase or not, derived from order information."
      ],
      "metadata": {
        "id": "pvg1I2Y5QC7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BigQuery dataset with feature engineering in SQL\n",
        "features = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  ARRAY(\n",
        "        CAST(u.age AS DOUBLE),\n",
        "        CAST(hash(u.country) AS BIGINT) * 1.0,\n",
        "        CAST(hash(u.gender) AS BIGINT) * 1.0,\n",
        "        CAST(hash(u.traffic_source) AS BIGINT) * 1.0\n",
        "    ) AS features,\n",
        "    CASE WHEN COALESCE(SUM(oi.sale_price), 0) > 0 THEN 1 ELSE 0 END AS label\n",
        "FROM users AS u\n",
        "LEFT JOIN order_items AS oi\n",
        "ON u.id = oi.user_id\n",
        "GROUP BY u.id, u.age, u.country, u.gender, u.traffic_source;\n",
        "\"\"\")\n",
        "features.show()"
      ],
      "metadata": {
        "id": "Le1JbxZPpEH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Perform ML Task**\n",
        "\n",
        "This code trains a logistic regression model to predict user purchase behavior, with these steps:\n",
        "\n",
        "**Feature Scaling:** StandardScaler scales the \"features\" column.\n",
        "\n",
        "**Model Initialization:** LogisticRegression is set up to predict the binary \"label\" (purchase/no purchase), with hyperparameters for training.\n",
        "\n",
        "**Pipeline Definition:** A Pipeline chains StandardScaler and LogisticRegression for streamlined scaling and training.\n",
        "\n",
        "**Model Training:** `pipeline.fit(dataset)` trains the pipeline (scaling and then the model).\n",
        "\n",
        "**Prediction:** `pipeline_model.transform(dataset)` generates predictions, and `transformed_dataset.show()` displays the results.\n",
        "\n",
        "In short, this step scales features, trains a logistic regression model within a pipeline, and produces purchase predictions."
      ],
      "metadata": {
        "id": "-Wj-0bASnK8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.connect.classification import LogisticRegression, LogisticRegressionModel\n",
        "from pyspark.ml.connect.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.connect.feature import StandardScaler\n",
        "from pyspark.ml.connect.pipeline import Pipeline\n",
        "\n",
        "#Split Train and Test Data (80:20)\n",
        "train_data, test_data = features.randomSplit([0.9, 0.1], seed=42)\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "lr = LogisticRegression(maxIter=30, learningRate=0.1, featuresCol=\"scaled_features\", labelCol=\"label\")\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[scaler, lr])"
      ],
      "metadata": {
        "id": "_4UXH0rLm6fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model.\n",
        "\n",
        "**Note**: If you see the following logging error, please ignore it: ```OSError: [Errno 99] Cannot assign requested address```"
      ],
      "metadata": {
        "id": "5dzndxJYOPsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "pipeline_model = pipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "G2T4T64rm_97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the dataset using the trained model\n",
        "transformed_dataset = pipeline_model.transform(test_data)\n",
        "\n",
        "# Print the new data\n",
        "transformed_dataset.show()"
      ],
      "metadata": {
        "id": "tV2JJ-t1ONES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Evaluation**\n",
        "\n",
        "This code evaluates the trained model's performance by:\n",
        "\n",
        "**Initializing an Evaluator:** A BinaryClassificationEvaluator is set up to calculate the Area Under the Precision-Recall Curve (AUC-PR).\n",
        "\n",
        "**Calculating AUC-PR:** The evaluate() method calculates the AUC-PR score using the model's predictions.\n",
        "\n",
        "This step quantifies the model's ability to distinguish between the two classes (e.g., purchase/no purchase).\n",
        "\n",
        "\n",
        "Further we will use NLP2SQL code generation to visualize the output\n",
        "\n",
        "**Prompt 1:** Generate code to plot the Precision-Recall (PR) curve. Calculate precision and recall from the model's predictions and display the PR curve using a suitable plotting library.\n",
        "\n",
        "**Prompt 2:** Generate code to create a confusion matrix visualization. Calculate the confusion matrix from the model's predictions and display it as a heatmap or a table with counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN)."
      ],
      "metadata": {
        "id": "7z9R-zu7nWtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "id": "P95v-u2ynZln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "eva = BinaryClassificationEvaluator(metricName=\"areaUnderPR\")\n",
        "aucPR = eva.evaluate(transformed_dataset)\n",
        "print(f\"AUC PR: {aucPR}\")"
      ],
      "metadata": {
        "id": "1PIlkb-Unatt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 7: Visualization**\n",
        "\n",
        "Let's visualize the results to see how our model performs, and how it has predicted.\n",
        "\n",
        "**Prompt 1:** Generate code to plot the Precision-Recall (PR) curve. Calculate precision and recall from the model's predictions and display the PR curve using a suitable plotting library.\n",
        "\n",
        "\n",
        "**Prompt 2:** Generate code to create a confusion matrix visualization. Calculate the confusion matrix from the model's predictions and display it as a heat map or a table with counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n"
      ],
      "metadata": {
        "id": "m5wsbhsAncHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to plot the Precision-Recall (PR) curve. Calculate precision and recall from the model's predictions and display the PR curve using a suitable plotting library.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import pandas as pd\n",
        "\n",
        "# Collect predictions and labels\n",
        "predictions = transformed_dataset.select(\"prediction\").toPandas()\n",
        "labels = transformed_dataset.select(\"label\").toPandas()\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision, recall, _ = precision_recall_curve(labels, predictions)\n",
        "\n",
        "# Plot the PR curve\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bt64dC_voJ5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to create a confusion matrix visualization. Calculate the confusion matrix from the model's predictions and display it as a heatmap or a table with counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Collect predictions and labels\n",
        "predictions = transformed_dataset.select(\"prediction\").toPandas()\n",
        "labels = transformed_dataset.select(\"label\").toPandas()\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "# Create a heatmap of the confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tkbv_5p0o51G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to plot the Precision-Recall (PR) curve. Calculate precision and recall from the model's predictions and display the PR curve using a suitable plotting library.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import pandas as pd\n",
        "\n",
        "# Convert Spark DataFrame to Pandas DataFrame\n",
        "transformed_pd = transformed_dataset.select(\"label\", \"prediction\").toPandas()\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision, recall, _ = precision_recall_curve(transformed_pd[\"label\"], transformed_pd[\"prediction\"])\n",
        "\n",
        "# Plot the PR curve\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T7xGUnBzVFhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate code to create a confusion matrix visualization. Calculate the confusion matrix from the model's predictions and display it as a heatmap or a table with counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'transformed_dataset' is a Spark DataFrame with 'label' and 'prediction' columns\n",
        "predictions_pd = transformed_dataset.select('label', 'prediction').toPandas()\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(predictions_pd['label'], predictions_pd['prediction'])\n",
        "\n",
        "# Create a heatmap visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Display the confusion matrix as a table\n",
        "cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
        "print(\"Confusion Matrix (Table):\", cm_df)\n",
        "\n",
        "# Extract TP, TN, FP, FN\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")"
      ],
      "metadata": {
        "id": "hnekNs7-Hgap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Convert feature list into individual columns\n",
        "pdf = features.select(\"features\", \"label\").toPandas()\n",
        "feature_df = pd.DataFrame(pdf[\"features\"].tolist(), columns=[\"age\", \"country_hash\", \"gender_hash\", \"traffic_source_hash\"])\n",
        "\n",
        "# Plot histograms\n",
        "feature_df.hist(figsize=(10, 6), bins=30, color=\"dodgerblue\", alpha=0.7)\n",
        "plt.suptitle(\"Feature Distributions\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GQJu8QLJkAvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 8: Write Predictions to BigQuery**\n",
        "\n",
        "Use Gemini to write predictions to BigQuery.\n",
        "\n",
        "**Prompt:** Using Spark, write the transformed dataset to BigQuery."
      ],
      "metadata": {
        "id": "ncZ55Z0sxF7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using Spark, write the transformed dataset to BigQuery.\n",
        "\n",
        "# Write the transformed dataset to BigQuery\n",
        "transformed_dataset.write.format(\"bigquery\").option(\"table\", f\"{PROJECT_ID}.my_dataset.predictions\").mode(\"overwrite\").save()"
      ],
      "metadata": {
        "id": "N1U-voG4xajv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}