{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table align=\"left\">\n",
        "  <td><a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/ai-ml-recipes/blob/main/notebooks/forecast/asset_price_forecast.ipynb\"><img src=\"https://avatars.githubusercontent.com/u/33467679?s=200&v=4\" width=\"32px\" alt=\"Colab logo\"> Run in Colab</a></td>\n",
        "  <td><a href=\"https://github.com/GoogleCloudPlatform/ai-ml-recipes/blob/main/notebooks/forecast/asset_price_forecast.ipynb\"><img src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" width=\"32px\" alt=\"GitHub logo\"> View on GitHub</a></td>\n",
        "  <td><a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/ai-ml-recipes/main/notebooks/forecast/asset_price_forecast.ipynb\"><img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> Open in Vertex AI Workbench</a></td>\n",
        "  <td><a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/GoogleCloudPlatform/ai-ml-recipes/blob/main/notebooks/forecast/asset_price_forecast.ipynb\"><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTW1gvOovVlbZAIZylUtf5Iu8-693qS1w5NJw&s\" alt=\"BQ logo\" width=\"35\"> Open in BQ Studio</a></td>\n",
        "  <td><a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fai-ml-recipes%2Fmain%2Fnotebooks/forecast/asset_price_forecast.ipynb\"><img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"> Open in Colab Enterprise</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Asset Price Forecasting with Apache Spark and Prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "This notebook demonstrates how to forecast asset prices using Apache Spark for data preparation and storage (Iceberg table) and Facebook Prophet for time series forecasting. It covers data loading, transformation, model training, forecasting, and saving the combined historical and forecasted data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Spark Session and Import Libraries\n",
        "This cell imports necessary libraries for Apache Spark data manipulation and defines the paths for input CSV and output Iceberg table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3535bf14-3152-4603-9ca2-1f4fc14400fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "from pyspark.sql.functions import make_date, col, year\n",
        "from pyspark.sql.functions import max\n",
        "\n",
        "csv_path = 'gs://<BUCKET_NAME>/public-data/finance/gc=f_price.csv'\n",
        "iceberg_path = \"gs://<BUCKET_NAME>/warehousing/finance/gc=f_price\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data\n",
        "Reads the asset price data from a CSV file into a Spark DataFrame, inferring the schema and including the header."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6797c4-e1be-4eca-9775-12e86128b81c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_path)\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimize and Prepare Data\n",
        "Drops unnecessary columns and extracts the year from the 'date' column, which will be used for partitioning the Iceberg table. Displays a sample of the optimized DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25618aa-f819-424b-a34b-695aa848f4a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_optimized = df.drop('High', 'Low', 'Open', 'Volume')\n",
        "df_optimized = df_optimized.withColumn('year', year(col('date')))\n",
        "df_optimized.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Processed Data to Iceberg\n",
        "Writes the optimized Spark DataFrame to an Apache Iceberg table, partitioning by year. The mode is set to 'overwrite' for initial setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a78a2c-3209-4356-92c9-a548d8f6c92b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_optimized.write.format('iceberg').mode('overwrite').partitionBy('year').saveAsTable('iceberg_catalog.finance.gold_price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Asset Price Forecasting with Prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert to Pandas DataFrame\n",
        "Converts the optimized Spark DataFrame to a Pandas DataFrame, which is required for the Prophet library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92137c35-0e0c-49bb-874a-b1bf5ab95e2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pandas = df_optimized.toPandas()\n",
        "df_pandas.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install and Import Forecasting Libraries\n",
        "Ensures the Prophet library is available and imports necessary modules for time series forecasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6053e59c-fd4c-4474-95a4-1bbeb0736b84",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install prophet\n",
        "import pandas as pd\n",
        "from prophet import Prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Data for Prophet and Train Model\n",
        "Renames columns to 'ds' (datestamp) and 'y' (value) as required by Prophet, initializes the Prophet model with a specified confidence interval, and trains the model on the historical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6daf8726-c67c-4c50-98a5-64cff93a2a14",
      "metadata": {},
      "outputs": [],
      "source": [
        "series = df_pandas.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
        "confidence_interval = 0.9\n",
        "model = Prophet(interval_width=confidence_interval)\n",
        "model.fit(series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Future Forecast\n",
        "Creates a DataFrame with future dates for a specified forecast period and generates predictions using the trained Prophet model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294ee85a-ee13-4700-a00e-986087f8926b",
      "metadata": {},
      "outputs": [],
      "source": [
        "forecast_period = 365\n",
        "future = model.make_future_dataframe(periods=forecast_period)\n",
        "forecast = model.predict(future)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize the Forecast\n",
        "Plots the historical data, fitted trend, and future forecast, including confidence intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3f253f-40c7-4208-9c7a-f4987b60e85c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "fig1 = model.plot(forecast)\n",
        "fig1.gca().set_title(\"Gold Spot Price Forecast\", size=16)\n",
        "fig1.gca().set_xlabel(\"Date\")\n",
        "fig1.gca().set_ylabel(\"Price USD/Ounce\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Forecasted Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Forecast Data for Integration\n",
        "Filters the forecast to include only future dates, renames columns to match the original DataFrame schema, converts the 'ds' column to a date type, and creates a Spark DataFrame from the forecast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea8fe86-0554-495c-9da2-df82a8dc1e55",
      "metadata": {},
      "outputs": [],
      "source": [
        "forecast1 = forecast[['ds', 'yhat']][forecast['ds']> '2025-07-17']\n",
        "forecast1.columns = ['Date', 'Close']\n",
        "forecast1['Date'] = forecast1['Date'].dt.date\n",
        "df_forecast = spark.createDataFrame(forecast1)\n",
        "df_forecast = df_forecast.withColumn('year', year(col('date')))\n",
        "df_forecast.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combine Original and Forecasted Data\n",
        "Unions the original historical Spark DataFrame with the newly generated forecast Spark DataFrame, ensuring schema compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c226ca-53a2-48c5-885c-83adba602be9",
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_df = df_optimized.unionByName(df_forecast)\n",
        "combined_df.tail(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Append Combined Data to Iceberg Table\n",
        "Appends the combined historical and forecasted data to the existing Apache Iceberg table, partitioning by year. This allows for unified storage and querying of both past and predicted values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6626681-753a-4162-83cb-61a0c5099108",
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_df.write.format('iceberg').mode('append').partitionBy('year').saveAsTable('iceberg_catalog.finance.gold_price')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Demo on Serverless Spark (Remote)",
      "language": "python",
      "name": "9c39b79e5d2e7072beb4bd59-runtime-0000524be569"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}